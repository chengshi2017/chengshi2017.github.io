<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[springboot 整合quartz实现定时任务]]></title>
    <url>%2F2018%2F05%2F17%2Fquartz%E5%9C%A8springboot%E4%B8%AD%E9%85%8D%E7%BD%AE%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;为了系统每天能够对用户的考勤数据进行检查，防止用户上午或者下午忘记打卡而影响了接下来的打卡操作，因此我们必须要在中午12点和晚上24:00设置一个定时任务对考勤数据进行检查。 &emsp;&emsp;在项目中，能够完成定时调度的方案有很多，例如在Java中，能够进行定时调度的方案有：ScheduledExecutorService和quartz两种，但是这两种本质上都是通过native中的wait方法来实现的。&emsp;&emsp;ScheduledExecutorService的Scheduled方法，其根据delay周期性的执行任务。其核心执行类和方法：其主要流程就是根据initTime和period时间计算出第一次执行的时间差，然后调用ReentrantLock.newCondition().awaitNanos(long nanosTimeout)方法，到指定的时间进行唤醒，分配线程进行执行。对于后续的周期性执行的await时间为period. 而quartz定时任务的调度是通过Object.wait方式(native方法)来实现的，其本质是通过操作系统的时钟来实现。原理在这里细讲，具体的调度流程可以参考百度。这里主要记录如何使用quartz实现定时任务的调度过程。 使用quartz实现定时任务的调度&emsp;&emsp;quartz 的设计者做了一个设计选择来从调度分离开作业。Quartz中的触发器用来告诉调度程序作业什么时候触发。框架提供了一把触发器类型，但两个最常用的是SimpleTrigger和CronTrigger。SimpleTrigger为需要简单打火调度而设计。典型地，如果你需要在给定的时间和重复次数或者两次打火之间等待的秒数打火一个作业，那么SimpleTrigger适合你。另一方面，如果你有许多复杂的作业调度，那么或许需要CronTrigger。 在我们日常的开发过程中，很多时候，定时任务都不是写死的，而是写到数据库中，实现定时任务的动态配置。 1.使用quartz时需要的maven依赖 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;4.3.11.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz-jobs&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt; 2.在项目中添加quartz.properties(这样就不会走自带的properties文件) 123456789101112131415161718192021222324252627282930313233343536# 固定前缀org.quartz# 主要分为scheduler、threadPool、jobStore、plugin等部分##org.quartz.scheduler.instanceName = DefaultQuartzSchedulerorg.quartz.scheduler.rmi.export = falseorg.quartz.scheduler.rmi.proxy = falseorg.quartz.scheduler.wrapJobExecutionInUserTransaction = false# 实例化ThreadPool时，使用的线程类为SimpleThreadPoolorg.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPool# threadCount和threadPriority将以setter的形式注入ThreadPool实例# 并发个数org.quartz.threadPool.threadCount = 5# 优先级org.quartz.threadPool.threadPriority = 5org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread = trueorg.quartz.jobStore.misfireThreshold = 5000org.quartz.scheduler.skipUpdateCheck=true# Job Store 方案2选1## 1. 默认存储在内存中#org.quartz.jobStore.class = org.quartz.simpl.RAMJobStore## 2. 持久化到数据库org.quartz.jobStore.class = org.quartz.impl.jdbcjobstore.JobStoreTXorg.quartz.jobStore.tablePrefix = QRTZ_org.quartz.jobStore.dataSource = qzDSorg.quartz.dataSource.qzDS.driver = com.mysql.jdbc.Driverorg.quartz.dataSource.qzDS.URL = jdbc:mysql://127.0.0.1:3306/quartz?useUnicode=true&amp;characterEncoding=UTF-8org.quartz.dataSource.qzDS.user = rootorg.quartz.dataSource.qzDS.password = Passw0rdorg.quartz.dataSource.qzDS.maxConnections = 10 3.在mysql数据库中创建quartz相关的表 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168## Quartz seems to work best with the driver mm.mysql-2.0.7-bin.jar## PLEASE consider using mysql with innodb tables to avoid locking issues## In your Quartz properties file, you&apos;ll need to set# org.quartz.jobStore.driverDelegateClass = org.quartz.impl.jdbcjobstore.StdJDBCDelegate#DROP TABLE IF EXISTS QRTZ_FIRED_TRIGGERS;DROP TABLE IF EXISTS QRTZ_PAUSED_TRIGGER_GRPS;DROP TABLE IF EXISTS QRTZ_SCHEDULER_STATE;DROP TABLE IF EXISTS QRTZ_LOCKS;DROP TABLE IF EXISTS QRTZ_SIMPLE_TRIGGERS;DROP TABLE IF EXISTS QRTZ_SIMPROP_TRIGGERS;DROP TABLE IF EXISTS QRTZ_CRON_TRIGGERS;DROP TABLE IF EXISTS QRTZ_BLOB_TRIGGERS;DROP TABLE IF EXISTS QRTZ_TRIGGERS;DROP TABLE IF EXISTS QRTZ_JOB_DETAILS;DROP TABLE IF EXISTS QRTZ_CALENDARS;CREATE TABLE QRTZ_JOB_DETAILS ( SCHED_NAME VARCHAR(120) NOT NULL, JOB_NAME VARCHAR(200) NOT NULL, JOB_GROUP VARCHAR(200) NOT NULL, DESCRIPTION VARCHAR(250) NULL, JOB_CLASS_NAME VARCHAR(250) NOT NULL, IS_DURABLE VARCHAR(1) NOT NULL, IS_NONCONCURRENT VARCHAR(1) NOT NULL, IS_UPDATE_DATA VARCHAR(1) NOT NULL, REQUESTS_RECOVERY VARCHAR(1) NOT NULL, JOB_DATA BLOB NULL, PRIMARY KEY (SCHED_NAME,JOB_NAME,JOB_GROUP));CREATE TABLE QRTZ_TRIGGERS ( SCHED_NAME VARCHAR(120) NOT NULL, TRIGGER_NAME VARCHAR(200) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, JOB_NAME VARCHAR(200) NOT NULL, JOB_GROUP VARCHAR(200) NOT NULL, DESCRIPTION VARCHAR(250) NULL, NEXT_FIRE_TIME BIGINT(13) NULL, PREV_FIRE_TIME BIGINT(13) NULL, PRIORITY INTEGER NULL, TRIGGER_STATE VARCHAR(16) NOT NULL, TRIGGER_TYPE VARCHAR(8) NOT NULL, START_TIME BIGINT(13) NOT NULL, END_TIME BIGINT(13) NULL, CALENDAR_NAME VARCHAR(200) NULL, MISFIRE_INSTR SMALLINT(2) NULL, JOB_DATA BLOB NULL, PRIMARY KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP), FOREIGN KEY (SCHED_NAME,JOB_NAME,JOB_GROUP) REFERENCES QRTZ_JOB_DETAILS(SCHED_NAME,JOB_NAME,JOB_GROUP));CREATE TABLE QRTZ_SIMPLE_TRIGGERS ( SCHED_NAME VARCHAR(120) NOT NULL, TRIGGER_NAME VARCHAR(200) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, REPEAT_COUNT BIGINT(7) NOT NULL, REPEAT_INTERVAL BIGINT(12) NOT NULL, TIMES_TRIGGERED BIGINT(10) NOT NULL, PRIMARY KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP), FOREIGN KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) REFERENCES QRTZ_TRIGGERS(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP));CREATE TABLE QRTZ_CRON_TRIGGERS ( SCHED_NAME VARCHAR(120) NOT NULL, TRIGGER_NAME VARCHAR(200) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, CRON_EXPRESSION VARCHAR(200) NOT NULL, TIME_ZONE_ID VARCHAR(80), PRIMARY KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP), FOREIGN KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) REFERENCES QRTZ_TRIGGERS(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP));CREATE TABLE QRTZ_SIMPROP_TRIGGERS ( SCHED_NAME VARCHAR(120) NOT NULL, TRIGGER_NAME VARCHAR(200) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, STR_PROP_1 VARCHAR(512) NULL, STR_PROP_2 VARCHAR(512) NULL, STR_PROP_3 VARCHAR(512) NULL, INT_PROP_1 INT NULL, INT_PROP_2 INT NULL, LONG_PROP_1 BIGINT NULL, LONG_PROP_2 BIGINT NULL, DEC_PROP_1 NUMERIC(13,4) NULL, DEC_PROP_2 NUMERIC(13,4) NULL, BOOL_PROP_1 VARCHAR(1) NULL, BOOL_PROP_2 VARCHAR(1) NULL, PRIMARY KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP), FOREIGN KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) REFERENCES QRTZ_TRIGGERS(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP));CREATE TABLE QRTZ_BLOB_TRIGGERS ( SCHED_NAME VARCHAR(120) NOT NULL, TRIGGER_NAME VARCHAR(200) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, BLOB_DATA BLOB NULL, PRIMARY KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP), FOREIGN KEY (SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) REFERENCES QRTZ_TRIGGERS(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP));CREATE TABLE QRTZ_CALENDARS ( SCHED_NAME VARCHAR(120) NOT NULL, CALENDAR_NAME VARCHAR(200) NOT NULL, CALENDAR BLOB NOT NULL, PRIMARY KEY (SCHED_NAME,CALENDAR_NAME));CREATE TABLE QRTZ_PAUSED_TRIGGER_GRPS ( SCHED_NAME VARCHAR(120) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, PRIMARY KEY (SCHED_NAME,TRIGGER_GROUP));CREATE TABLE QRTZ_FIRED_TRIGGERS ( SCHED_NAME VARCHAR(120) NOT NULL, ENTRY_ID VARCHAR(95) NOT NULL, TRIGGER_NAME VARCHAR(200) NOT NULL, TRIGGER_GROUP VARCHAR(200) NOT NULL, INSTANCE_NAME VARCHAR(200) NOT NULL, FIRED_TIME BIGINT(13) NOT NULL, SCHED_TIME BIGINT(13) NOT NULL, PRIORITY INTEGER NOT NULL, STATE VARCHAR(16) NOT NULL, JOB_NAME VARCHAR(200) NULL, JOB_GROUP VARCHAR(200) NULL, IS_NONCONCURRENT VARCHAR(1) NULL, REQUESTS_RECOVERY VARCHAR(1) NULL, PRIMARY KEY (SCHED_NAME,ENTRY_ID));CREATE TABLE QRTZ_SCHEDULER_STATE ( SCHED_NAME VARCHAR(120) NOT NULL, INSTANCE_NAME VARCHAR(200) NOT NULL, LAST_CHECKIN_TIME BIGINT(13) NOT NULL, CHECKIN_INTERVAL BIGINT(13) NOT NULL, PRIMARY KEY (SCHED_NAME,INSTANCE_NAME));CREATE TABLE QRTZ_LOCKS ( SCHED_NAME VARCHAR(120) NOT NULL, LOCK_NAME VARCHAR(40) NOT NULL, PRIMARY KEY (SCHED_NAME,LOCK_NAME));commit; 4.项目中quartz结构示意图 5.实体类 1234567891011121314@Entity@Tablepublic class ScheduleJob &#123; @Id @GeneratedValue(strategy = GenerationType.AUTO) private Long id; private String jobName; private String cronExpression; private String springId; private String methodName; private String jobStatus; //省略getter和setter方法 6.任务类 123456789@Configuration@EnableSchedulingpublic class TaskConfiguration &#123; @Bean public SchedulerFactoryBean schedulerFactoryBean()&#123; return new SchedulerFactoryBean(); &#125;&#125; 7.任务实现类 123456789101112131415161718192021222324252627282930313233343536373839404142@Service@Transactionalpublic class TaskServiceImpl implements ITaskService &#123; @Autowired private SchedulerFactoryBean schedulerFactoryBean; @Autowired private ScheduleJobRepository scheduleJobRepository; @Override public void timingTask() &#123; //查询数据库是否存在需要定时的任务 List&lt;ScheduleJob&gt; scheduleJobs = scheduleJobRepository.findAllByJobStatus(&quot;1&quot;); if (scheduleJobs != null) &#123; scheduleJobs.forEach(this::execute); &#125; &#125; //添加任务 private void execute(ScheduleJob scheduleJob)&#123; try &#123; //声明调度器 Scheduler scheduler = schedulerFactoryBean.getScheduler(); //添加触发调度名称 TriggerKey triggerKey = TriggerKey.triggerKey(scheduleJob.getJobName()); //设置触发时间 CronScheduleBuilder cronScheduleBuilder = CronScheduleBuilder.cronSchedule(scheduleJob.getCronExpression()); //触发建立 Trigger trigger = TriggerBuilder.newTrigger().withIdentity(triggerKey).withSchedule(cronScheduleBuilder).build(); //添加作业名称 JobKey jobKey = JobKey.jobKey(scheduleJob.getJobName()); //建立作业 JobDetail jobDetail = JobBuilder.newJob(QuartzFactory.class).withIdentity(jobKey).build(); //传入调度的数据，在QuartzFactory中需要使用 jobDetail.getJobDataMap().put(&quot;scheduleJob&quot;,scheduleJob); //调度作业 scheduler.scheduleJob(jobDetail,trigger); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125;&#125; &emsp;&emsp;通过上述代码查询数据库中存在的定时任务，因为项目中使用了jpa技术，查询语句直接使用了jpa自带的接口。查询到定时任务之后，将任务添加到项目中。 7.自定义需要定时启动的job1234567891011121314@Service(&quot;taskInfo&quot;)@Transactionalpublic class TaskInfoServiceImpl implements ITaskInfoService &#123; @Autowired private AttendService attendService; @Override public void execute() &#123; System.out.println(&quot;任务执行开始===============任务执行开始&quot;); attendService.checkAttend(); System.out.println(&quot;任务执行结束===============任务执行结束&quot;); &#125;&#125; &emsp;&emsp;上述代码中的checkAttend()接口即需要定时启动的job. 8.检查用户考勤数据的接口 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Override public void checkAttend() &#123; /** * 第一种情况，上下午都没有打卡，调用自动执行任务，将打卡记录补上， * 记为缺勤一整天，状态为异常 */ List&lt;String&gt; userIdList = attendMapper.getUserIdAbsence(); if (CollectionUtils.isNotEmpty(userIdList))&#123; List&lt;Attend&gt; list = new ArrayList&lt;&gt;(); for (String userId : userIdList)&#123; Attend attend = new Attend(); attend.setUserId(userId); attend.setAttendId(UUID.getUUID()); attend.setUserAttendId(UUID.getUUID()); attend.setAttendDate(DateUtils.getCurrentDay()); attend.setAttendWeek(DateUtils.getCurrentWeek()); //拼装备注信息 //根据用户Id查询用户名称 String userName=userMapper.getUserByUserId(userId).getUserName(); String currentDay=DateUtils.getCurrentDay(); attend.setRemark(userName+&quot;-&quot;+currentDay+&quot;打卡记录&quot;); attend.setAbsence(Constants.AttendConstants.ABSENCE_DAY); attend.setAttendStatus(Constants.AttendConstants.ATTEND_STATUS_ABNORMAL); list.add(attend); &#125; //打卡记录表批量插入 attendMapper.batchInsert(list); //关联记录表批量插入 userAttendMapper.batchInsert(list); &#125; /** * 第二种情况：上午完成了打卡，但是晚上忘记了打卡 * 同样将缺勤时间记为240分钟，状态记为异常 */ List&lt;Attend&gt; attendList=attendMapper.getTodayEveningAbsence(); //将状态置为0，缺勤240分钟 if (CollectionUtils.isNotEmpty(attendList))&#123; for (Attend attend:attendList)&#123; attend.setAttendStatus(Constants.AttendConstants.ATTEND_STATUS_ABNORMAL); attend.setAbsence(attend.getAbsence()+Constants.AttendConstants.ABSENCE_DAY/2); attendMapper.updateByPrimaryKeySelective(attend); &#125; &#125; &#125; 9.准备存放定时任务的数据库表 123456789101112131415161718SET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------ Table structure for schedule_job-- ----------------------------DROP TABLE IF EXISTS `schedule_job`;CREATE TABLE `schedule_job` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `cron_expression` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL, `job_name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL, `job_status` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL, `method_name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL, `spring_id` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL, PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;SET FOREIGN_KEY_CHECKS = 1; 在数据库中如下图所示配置：说明：cron_expression的参数解释：从左到右分别是：秒，分，时，月的某天，月，星期的某天，年；其中年不是必须的，也就是说任何一个表达式最少需要六项。先看示列：”0 0/30 8-10 5,20 ?” 表示“每个月的5日和20日的8:00,8:30,9:00,9:30,10:00,10:30”字符解释：,：与，表式”,”两边的值都是需要执行的时间，如上例”5,20”，每个月的5日与20日。-：表示值的范围，如上例”8-10”，从8点开始到10结束，包括8点与10点。 ：表式任意可合法的值，如上例”*”是处于月份的字段，所以代表1-12中的任意值，所以上例是指“每个月”。/：增量，如上例是指从0分开始，每过30分钟取一次值。如果换成”5/8”就是从第5钟开始每过8分钟取一次值：8:05,8:13,8:21,8:29等等?：不指定值，就是“我也不知道”的意思，只能出现在“月的某天，星期的某天”项中。在什么情况下用呢？如上例如果指定值为星期一，那么可能会出现如4月5日不是星期一，这里就是不对应，有冲突，所以指定为”?”，也就是说我也不知道是星期几，只要是5日与20日就行了，至于是星期几我才不管呢！L：最后的，last的意思，只能出现在“月的某天，星期的某天”项中。表示当前月或当前星期的最后一天，注意的是星期的最后一天为星期六。W：月中最接近指定日期的普通日（星期一到星期五），只能出现在“月的某天”，如”15W”就是说当前月最接近15日的普通日，如果当月的15是星期三就是星期三，如果当月的15是星期六那么就是昨天也就是星期五，如果当月的15是星期天则为第二天也就是星期一。注意：当前月的第N个星期X日，只能出现在“星期的某天”项中。如”6#3”就是说当前月的第三个星期五，注意”1-7”，1=星期天，2=星期一 等等。 （部分内容来自互联网） 10.启动项目，即可看到任务开始执行 项目运行过程中遇到的问题： 1.在shiro 中自带了quartz，不过版本是1.6.1。这就导致了quartz目前的版本2.3.0与shiro存在兼容性的问题。这个问题的解决方案参考. 2.在项目中整合进quartz之后，报错123严重 : Exception sending context initialized event to listener instance of class org.springframework.web.context.ContextLoaderListenerorg.springframework.beans.factory.BeanCreationException : Error creating bean with name &apos;cronTriggerPunch&apos; defined in ServletContext resource [/WEB-INF/applicationContext-attend.xml]: Cannot create inner bean &apos;org.springframework.scheduling.quartz.JobDetailBean#15e92d7&apos; of type [org.springframework.scheduling.quartz.JobDetailBean] while setting bean property &apos;jobDetail&apos;; nested exception is org.springframework.beans.factory.BeanCreationException : Error creating bean with name &apos;org.springframework.scheduling.quartz.JobDetailBean#15e92d7&apos; defined in ServletContext resource [/WEB-INF/applicationContext-attend.xml]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException : Could not instantiate bean class [org.springframework.scheduling.quartz.JobDetailBean]: Constructor threw exception; nested exception is java.lang.NoSuchMethodError: org.apache.commons.collections.SetUtils.orderedSet(Ljava/util/Set;)Ljava/util/Set; 网上百度之后成功解决，检查代码完全正确，没有什么问题，思考着那么就可能是jar包出现问题，一般情况下应该是commons-collections的版本太低，升级之后还是报错。后来去掉了WEB-INF/lib/ 下的cglib-2.1.3.jar包，问题成功解决。]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>web项目</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[velocity 基本语法]]></title>
    <url>%2F2018%2F05%2F15%2Fvelocity%E6%A8%A1%E6%9D%BF%E8%AF%AD%E8%A8%80%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;velocity 是一个基于Java的模板引擎框架，它允许任何人使用简单而强大的模板语言来引用定义在Java代码中的对象。 优点velocity相比于jsp有如下优点： velocity将Java代码从网页中分离出来，使页面开发者专注于前端页面的开发，后端设计者专注于代码的书写，很好的实现了前后端分离。 velocity加载速度远远优于jsp。原因在渲染机制时再说。 velocity最大的优点是采用了模板缓冲技术，在模板缓冲机制的作用下，模板不再是每次请求都从磁盘中获取，更多的是在缓冲区保存和解析，当我们在开发过程中，一般是禁用缓存的，因为此时页面较少同时也要求页面实施更新，当我们开发完成之后，此时就要启用缓存了，所以velocity的加载速度远远高于jsp。 渲染机制&emsp;&emsp;velocity的加载速度之所以远远优于jsp，主要原因是二者的加载方式不同，下面分别来一一介绍： 1 jsp的加载方式主要是先将jsp页面编译成servlet,再由servlet处理用户的请求JSP容器管理JSP页面生命周期分为两个阶段：转换阶段和执行阶段，当有一个对JSP页面的客户请求到来时，JSP容器将JSP页面转换为Servlet源文件，然后调用javac工具编译源文件生成字节码文件，接下来，Servlet容器加载转换后的Servlet类，实例化一个对象处理客户端的请求，请求处理完成后响应对象被JSP容器接收，容器将HTML格式的响应信息发送给客户端。 2 velocity 将页面代码解析成语法树:velocity 渲染这段代码将从根节点ASTproces开始，按照深度优先遍历算法开始遍历整棵树。Velocity的语法相对简单，所以它的语法节点并不是很多，总共有50几个，它们可以划分为如下几种类型。&emsp;&emsp;1. 块节点类型：主要用来表示一个代码块，它们本身并不表示某个具体的语法节点，也不会有什么渲染规则。这种类型的节点主要由ASTReference、ASTBlock和ASTExpression等组成。&emsp;&emsp;2. 扩展节点类型：这些节点可以被扩展，可以自己去实现，如我们上面提到的#foreach，它就是一个扩展类型的ASTDirective节点，我们同样可以自己再扩展一个ASTDirective类型的节点。&emsp;&emsp;3. 中间节点类型：位于树的中间，它的下面有子节点，它的渲染依赖于子节点才能完成，如ASTIfStatement和ASTSetDirective等。&emsp;&emsp;4. 叶子节点：它位于树的叶子上，没有子节点，这种类型的节点要么直接输出值，要么写到writer中，如ASTText和ASTTrue等。Velocity读取vm模板根据JavaCC语法分析器将不同类型的节点按照上面的几个类型解析成一个完整的语法树。&emsp;&emsp;在调用render方法之前，Velocity会调用整个节点树上所有节点的init方法来对节点做一些预处理，如变量解析、配置信息获取等。这非常类似于Servlet实例化时调用init方法。Velocity在加载一个模板时也只会调用init方法一次，每次渲染时调用render方法就如同调用Servlet的service方法一样。 语法及使用&emsp;&emsp;当我们需要在web应用中使用velocity，首先需要配置velocity，这里以spring boot为例。(由于spring 4.x开始不支持velocity，所以spring boot版本要在1.4.0之前)。&emsp;&emsp;在springboot中配置velocity很简单，只需要在配置文件application.yml中加上如下配置即可1234567spring: velocity: charset: UTF-8 resource-loader-path: classpath:/templates/ suffix: .vm toolbox-config-location: configs/toolbox.xml check-template-location: true &emsp;&emsp;以上配置了velocity模板语言的编码格式为:UTF-8,文件存在于/templates目录下，文件的后缀为.vm文件 基本语法 1 “#”用法“#”表示velocity脚本语句，常用的有: #parse、#set、#if、#else、#end、#foreach、#marco。用法如下所示： 2 “$”用法“$”表示velocity变量。$msg $item等都表示为变量。 3 “!”用法“!”表示当变量为空时，强制将变量置为空。通常和”$”一起用，$!msg 表示将msg信息打印出来，如果msg变量为空，不是在页面中显示“msg”字符，而是强制将msg置为空。 4 “{}”用法“{}”用来标识velocity变量，常于”$”连用，例如${msg}。 脚本语句 1 #parse&emsp;&emsp;表示将其它文件引用到当前文件中，常用于事先定义好页面中需要引用的css、js文件，将其独立定义到一个文件中，然后在多个文件中引用此文件。例如：12#parse &quot;common/header.vm&quot;#parse &quot;common/footer.vm&quot; &emsp;&emsp;以上例子中的header.vm和footer.vm表示即为事先定义好的头文件和尾文件，里面引用了大量的css、js文件，使用#parse即可将其引入。#parse可以有效地减少页面冗余。 2 #set&emsp;&emsp;#set主要是用于在页面中定义变量或者向一个变量或者属性赋值，其格式为：#set($foo=”bar”)或者#set($foo.bar=$test) 。12##设置总页数#set($pages = $lists.pages) &emsp;&emsp;注意：在万不得已的时候，不要在页面视图自己声明Velocity脚本变量，也就是尽量少使用#set。有时候我们需要在页面中显示序号，而程序对象中又没有包 含这个序号属性同，可以自己定义。 3 #if 、#else&emsp;&emsp;#if一般都是和#else组合在一起使用，表示一组条件语句的判断，后面还常常跟着#end.123456789#if($msg)&lt;script&gt;alert(&apos;$!msg&apos;);&lt;/script&gt;#else&lt;script&gt;alert(&apos;111&apos;);&lt;/script&gt;#end &emsp;&emsp;以上的脚本表示当对象msg存在时打印出msg的内容，不存在时输出111 4 #foreach&emsp;&emsp;#foreach在页面中使用比较多，表示循环读取list集合中的内容，并进行相应的处理123456789101112#foreach($menu in $menus) &lt;dl id=&quot;menu-$!menu.menuId&quot;&gt; &lt;dt&gt;&lt;i class=&quot;Hui-iconfont&quot;&gt; $!menu.menuIcon &lt;/i&gt; $!menu.menuName &lt;i class=&quot;Hui-iconfont menu_dropdown-arrow&quot;&gt;&amp;#xe6d5;&lt;/i&gt;&lt;/dt&gt; &lt;dd&gt; &lt;ul&gt; #foreach($menuItem in $menu.listMenus) &lt;li&gt;&lt;a _href=&quot;$!menuItem.menuUrl&quot; data-title=&quot;$!menuItem.menuName&quot; href=&quot;javascript:void(0)&quot;&gt;$!menuItem.menuName&lt;/a&gt;&lt;/li&gt; #end &lt;/ul&gt; &lt;/dd&gt; &lt;/dl&gt;#end &emsp;&emsp;以上代码表示遍历menus中的内容，然后在页面上显示相对应的菜单信息，实现动态菜单的显示。 5 #macro&emsp;&emsp;#macro(macroName)#end 脚本函数(宏)调用，不推荐在界面模板中大量使用。12345#macro(orderPic $type)#if ($orderField.equals($type))&lt;img src=&quot;http://images.cnblogs.com/ico/$&#123;orderType&#125;.gif&quot;&gt;#end#end &emsp;&emsp;具体的调用如：头衔#orderPic(“title”)。经过测试，宏不支持方法重载 velocity其它用法 1 逻辑运算符&emsp;&emsp;velocity中逻辑运算符主要包括以下几种: == 、&amp;&amp;、 ||、 ！用法和Java中一样。 2 $velocityCount&emsp;&emsp;这个变量在velocity属性文件中定义，在#foreach的时候可以用得上，比如我foreach一个List时，我们可以使用$velocityCount判断完成形如“张三，李四”的输出(李四后面没有逗号) 3 注释&emsp;&emsp;单行## XXX&emsp;&emsp;多行#* xxx 4 #stop 停止执行并返回 5 定义宏Velocimacros ,相当于函数 支持包含功能12345#macro( d )&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;#end调用#d()]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>模板引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自动化运维工具SaltStack安装使用教程]]></title>
    <url>%2F2018%2F04%2F11%2F%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4%E5%B7%A5%E5%85%B7SaltStack%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;系统自动化管理和配置工具SaltStack采用zeromq消息队列进行通信，和Puppet比起来，SaltStack速度快得多。目前SaltStack处于快速发展阶段，可以看做是强化的Func+弱化的Puppet的组合这也间接的反映出了SaltStack的两大功能：远程执行和配置管理。 SaltStack的安装配置&emsp;&emsp;和大多数类似工具一样，SaltStack是一个基于C/S的远程控制软件，需要在一台机器（主控）上安装服务端软件（salt-master），在需要被控制的机器（受控）上安装客户端软件（salt-minion）。受控机器可以有多台，但是主控机器只能有一台。当在主控机器上给受控机器发指令，在受控机器上执行主控机器发出的指令。&emsp;&emsp;说明：由于项目上的需要，salt-master安装在服务器上（172.17.20.140（Linux机器）），受控端安装了两台机器，一台是本机用作测试用，另一台安装在需要被调控的服务器上（192.168.5.252（Windows机器）） 服务端salt-master的安装&emsp;&emsp;首先安装salt-master 运行所需要的依赖，因为SaltStack使用Python写的，所以必须系统必须安装Python环境。123$ yum install python-jinja2 -y$ yum install m2cryto -y$ wget http://pyyaml.org/download/libyaml/yaml-0.1.6.tar.gz 解压并安装yaml1234$ tar zvxf yaml-0.1.6.tar.gz$ cd yaml-0.1.6$ ./configure$ make&amp;&amp;make install 导入yum源1$ rpm -Uvh http://mirror.pnl.gov/epel/6/i386/epel-release-6-8.noarch.rpm 安装salt-master1$ yum install salt-master -y 直接运行下列命令修改salt-master 配置12$ sed -i &apos;s/#interface: 0.0.0.0/interface: 172.17.20.140/g&apos; /etc/salt/master$ sed -i &apos;s/#hash_type: md5/hash_type: sha256/g&apos; /etc/salt/master &emsp;&emsp;说明：上面第一条命令表示将/etc/salt/master中的’#interface: 0.0.0.0’替换为’interface: 172.17.20.140’。’/g’表示全部替换。第二条命令表示将/etc/salt/master中的’#hash_type: md5’替换为’hash_type: sha256’。同样’/g’表示全部替换。修改完salt-master配置后使用命令启动1234$ service salt-master start# CentOS7以上使用如下两条命令：# systemctl enable salt-master.service# systemctl start salt-master.service 启动后查看saltstack master服务状态12$ service salt-master status($ systemctl status salt-master.service) 出现如图所示情况表示安装成功 在本地Windows机器上安装salt-minion客户端&emsp;&emsp;下载相应版本的salt-minion(salt-minion可以安装在多种环境的机器上，但是salt-master只能安装在Linux环境下，现在暂时没有salt-master在Windows下的安装包)https://repo.saltstack.com/windows/Salt-Minion-2018.3.0-Py2-AMD64-Setup.exe注意要对应上系统的Python版本（下载可能需要翻墙）。下载安装包后点击安装，一路next即可，配置信息直接在/salt/conf/minion中修改在Windows下配置salt-minion只需要修改两个地方的配置即可，打开/salt/conf/minion12master: 172.17.20.140id: Admin-pc 说明：master指定salt-master 的地址，id作为当前salt-minion的标识。启动salt-minion：进入salt根目录，先点击salt-minion-start-service.bat文件，然后点击salt-minion.bat验证是否启动salt-minion：在命令行窗口输入services.msc如果存在salt-minion服务并且已经启动，表示salt-minion启动成功。 验证SaltStack是否能够正常通信在master和minion端的服务启动后都会生成公钥和私钥，此时需要在master端使用salt-key命令接受minion公钥配置密钥认证，完成后即可对minion进行管理。salt-key的命令参数主要有：-L&emsp;&emsp;&emsp;&emsp; 会显示所有minion公钥，不加任何参数也相当于-L的效果-a&emsp;&emsp;&emsp;&emsp; 许可指定的公钥，后面要指定你允许的minion的id名-A&emsp;&emsp;&emsp;&emsp; 许可所有minion的公钥-r&emsp;&emsp;&emsp;&emsp; 拒绝指定的公钥-R&emsp;&emsp;&emsp;&emsp; 拒绝所有pending的公钥-d&emsp;&emsp;&emsp;&emsp; 根据公钥的名称删除公钥，删除指定的minion-D&emsp;&emsp;&emsp;&emsp; 删除所有公钥，删除所有已经认证的minion-y&emsp;&emsp;&emsp;&emsp; 对所有询问是否继续，回答yes SaltStack远程执行命令1.使用test.ping测试网络的连通性说明：由于公司252服务器关闭了，所以salt-master并没有找到252上面的salt-minion，手工测试ping252也没有成功2.SaltStack常用命令CentOS远程执行命令： salt ‘minion_147’ cmd.run ‘hostname’CentOS远程执行脚本：（脚本是位于minion端/opt/SaltStack/Scripts目录下的helloSalt.sh） salt ‘minion_147’ cmd.run ‘/opt/SaltStack/Scripts/helloSalt.sh’win7远程执行命令： salt ‘windows7’ cmd.run ‘tasklist|find “shell”‘win7远程执行脚本：（该脚本位于C:\salt\bat目录下的helloSalt.bat） salt ‘windows7’ cmd.run cmd=’helloSalt.bat’ cwd=’C:\salt\bat’ 疑惑和思考1.master和minion之间是怎么通信的？&emsp;&emsp;在安装完成后，查看了下端口，发现主控服务器上salt-master上打开了4505和4506端口，可是被控服务器salt-minion上没有打开任何的端口，百思不得其解，网上查了一波终于明白了。SaltStack默认使用zeromq传递消息，zeromq会随着SaltStack的安装而安装，它是一个消息队列服务，master通过4505端口将指令放到zeromq中，而所有的minion都会监听master的4505端口，然后从队列中拿消息进行对比决定是否进行操作，如果操作将自己操作的结果丢回zeromq另外一个队列，master从4506端口监听该队列，得到返回结果，然后展示出来 2.minion如何修改id当minion的id变更后，我们需要进行如下操作：1234561 minion端停止salt-minion2 master端salt-key –d 原本minion的id3 minion端删除/etc/salt/pki/minion下所有文件4 minion端修改配置文件中的id变成需要的新id5 重启minion端的salt-minion6 master端认证接受新的id]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins集成Sonar进行持续审查]]></title>
    <url>%2F2018%2F04%2F06%2FJenkins%E9%9B%86%E6%88%90Sonar%E8%BF%9B%E8%A1%8C%E6%8C%81%E7%BB%AD%E5%AE%A1%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;由于最近客户要求在devops持续集成平台上增加代码审计功能，经过一番对比，决定选用sonar来实现，通过网上的文档艰难的完成了安装，写篇博客记录下。 SonarQube 简介&emsp;&emsp;Sonar是一个用于代码质量管理的开源平台，用于管理Java源代码的质量。通过插件机制，Sonar 可以集成不同的测试工具，代码分析工具，以及持续集成工具，比如pmd-cpd、checkstyle、findbugs、Jenkins。通过不同的插件对这些结果进行再加工处理，通过量化的方式度量代码质量的变化，从而可以方便地对不同规模和种类的工程进行代码质量管理。同时 Sonar 还对大量的持续集成工具提供了接口支持，可以很方便地在持续集成中使用 Sonar。 此外，Sonar 的插件还可以对 Java 以外的其他编程语言提供支持，对国际化以及报告文档化也有良好的支持。Sonar可以从以下七个维度检测代码质量，而作为开发人员至少需要处理前5种代码质量问题&emsp;&emsp;1.不遵循代码标准&emsp;&emsp;sonar可以通过PMD,CheckStyle,Findbugs等等代码规则检测工具规范代码编写&emsp;&emsp;2.潜在的缺陷&emsp;&emsp;sonar可以通过PMD,CheckStyle,Findbugs等等代码规则检测工具检测出潜在的缺陷&emsp;&emsp;3.糟糕的复杂度分布&emsp;&emsp;文件、类、方法等，如果复杂度过高将难以改变，这会使得开发人员难以理解它们且如果没有自动化的单元测试，对于程序中的任何组件的改变都将可能导致需要全面的回归测试&emsp;&emsp;4.重复&emsp;&emsp;显然程序中包含大量复制粘贴的代码是质量低下的，sonar可以展示源码中重复严重的地方&emsp;&emsp;5.注释不足或者过多&emsp;&emsp;没有注释将使代码可读性变差，特别是当不可避免地出现人员变动时，程序的可读性将大幅下降而过多的注释又会使得开发人员将精力过多地花费在阅读注释上，亦违背初衷&emsp;&emsp;6.缺乏单元测试&emsp;&emsp;sonar可以很方便地统计并展示单元测试覆盖率&emsp;&emsp;7.糟糕的设计&emsp;&emsp;通过sonar可以找出循环，展示包与包、类与类之间的相互依赖关系，可以检测自定义的架构规则通过sonar可以管理第三方的jar包，可以利用LCOM4检测单个任务规则的应用情况， 检测耦合。 SonarQube与Sonar-Scanner的安装与配置下载sonarQube安装包&emsp;&emsp;SonarQube可以在官网(https://www.sonarqube.org/downloads/)下载，在Linux服务器上安装始终加载不到静态文件，所以最后决定直接在Windows服务器上安装sonar，将从官网下载的安装包解压到任意目录。 创建sonar数据库&emsp;&emsp;SonarQube自带了一个H2数据库，但是为了获得更好的性能还是选择MySQL数据库。首先在mysql中新建一个sonar数据库，用于存放分析的数据，并且新建一个数据库用户，实测直接用root账户会报错。1234&gt; CREATE USER 'sonar'@'%' IDENTIFIED BY 'password';&gt; GRANT all privileges ON sonarqube.* TO sonar'@''%' IDENTIFIED BY 'password';&gt; flush privileges;&gt; create database sonar; 注意：MySQL数据库一定要在5.6以上(sonar要求数据库支持事务，mysql5.6+才是InnerDB) 配置sonar应用mysql&emsp;&emsp;修改配置文件sonar.properties123456sonar.jdbc.username=sonarsonar.jdbc.password=sonarsonar.jdbc.url=jdbc:mysql://172.17.20.140:3307/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance&amp;useSSL=falsesonar.web.host=0.0.0.0sonar.web.context=/sonarsonar.web.port=9000 保存配置文件后，进入\bin\windows-x86-64目录下，双击startup.bat启动。如果启动过程没有报错，打开浏览器输入http://172.17.20.125:9000/sonar/，出现如下画面说明安装成功 配置Sonar-Scanner 进行项目代码审查&emsp;&emsp;下载sonar-scanner，解压到任意目录，同样的修改sonar.properties 配置文件12# --------指定系统中sonar访问路径sonar.host.url=http://localhost:9000/sonar 如果安装的不是同一台机器，将localhost修改为对应地址即可sonar-scanner在项目中使用需要在项目根目录下添加sonar-project.properties文件12345678#sonar-project.properties内容如下sonar.projectKey=project_keysonar.projectName=project_namesonar.projectVersion=1.0sonar.sources=./sonar.language=py //需要扫描哪种语言的代码，如python:py，java:javasonar.sourceEncoding=UTF-8sonar.host.url=http://your_host:your_port/[your_prefix] 进入项目根目录，启动cmd命令行，输入sonar-scanner，sonar-scanner会自动对项目进行检查，检查的结果发送到sonar服务器进行解析，然后反馈的用户。 将sonar集成到jenkins中&emsp;&emsp;将sonar配置到jenkins中，当使用jenkins自动化部署项目时，就能够自动的对代码进行检查1.手动下载jenkins插件SonarQube Scanner for Jenkins。也可以直接在jenkins中下载，在[Manage Jenkins]-[Global Tool Configuration]中配置JDK和Maven后，再在Jenkins上安装SonarQube插件。在[Manage Jenkins]-[Global Tool Configuration]中选择SonarQube Scanner for Jenkins插件，点击下载，下载完成后重启jenkins服务器。2.jenkins重启成功后，打开[Manage Jenkins]-[Configure System]和[Manage Jenkins]-[Global Tool Configuration]，可以看到新增了Sonar Qube的选项。在[Manage Jenkins]-[Configure System]中配置SonarQube Server。[Server authentication token]行对应的token请输入第一次启动sonar server时生成的token 在jenkins中配置sonar进行代码审查&emsp;&emsp;完成好以上步骤后，在进行项目编译打包时，点击[增加构建步骤]，会发现多了Execute SonarQube Scanner选项在Execute SonarQube Scanner中进行如下配置： Task to run 可以随便写，JDK一定要选择jenkins 中配置的jdk(版本不能太低，sonar要求jdk版本为1.8)，Path to project properties: 相当于sonar-scanner中的sonar-project.properties，如果在项目的根目录下有sonar-scanner配置文件配置即可。Additional arguments中可写可不写，个人习惯加上“-X”,表示以Debug的形式启动，能够显示更多的信息。Analysis properties示例如下图所示：123456sonar.projectKey=$proNamesonar.projectName=$proNamesonar.projectVersion=1.0sonar.sources=$&#123;proName&#125;/srcsonar.language=java sonar.sourceEncoding=UTF-8 在sonar-java插件4.10版本之后，还需要添加sonar.java.binaries=target/classes。但是因为打包时可能没有编译后的文件，所以我在sonarqube中替换了sonar-java-plugin文件，将版本改为4.10。 保存好Execute SonarQube Scanner配置，开始编译打包，查看日志 然后打开sonarqube server,即可查看分析结果 关于启动与关闭的问题&amp;&emsp;&emsp;sonar 如果安装在Linux服务器下，启动和关闭都不是问题，进入sonar安装目录的bin文件夹的Linux-x86-64目录下，直接使用命令启动1234# 启动sonar$ ./sonar.sh start# 关闭sonar$ ./sonar.sh stop 哎！公司服务器抽风，Linux安装一直出现静态资源没法加载，估计是环境的问题，但是没法改，只能在Windows服务器上安装。在Windows中启动比在Linux中更简单，直接进入安装目录下的[E:\sonarqube-6.7.3\bin\windows-x86-64]目录下，双击startSonar.bat启动。(选择Windows-x86-64还是32，根据系统中安装的jdk版本而定，必须跟jdk版本对应，Linux中同理)。Windows中启动简单，但是关闭却比较复杂，各种关联文件，一个个的都必须释放才能彻底关闭。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jquery+ajax实现数据的批量删除]]></title>
    <url>%2F2018%2F03%2F28%2Fjquery%2Bajax%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E7%9A%84%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;在写项目的时候，由于数据比较多，删除数据的时候一个一个的点击删除比较麻烦，所以准备在项目中使用批量删除的功能。批量删除在项目中的实现比较简单。 批量删除功能的实现主要难度是在前端，在后端只需要用mybatis做一个批量删除的接口就行。 1.增加表格数据勾选框如果要在表格数据中实现批量删除，那么最基本的需要一个勾选框，选中了数据之前的勾选框才会进行删除。因此我们首先要在表格中加入勾选框，代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 &lt;table class=&quot;table table-border table-bordered table-bg table-hover table-sort&quot;&gt; &lt;thead&gt; &lt;tr class=&quot;text-c&quot;&gt; &lt;th width=&quot;25&quot;&gt;&lt;input type=&quot;checkbox&quot; name=&quot;subCheck&quot; id=&quot;subCheck&quot;/&gt;&lt;/th&gt; &lt;th width=&quot;40&quot;&gt;序号&lt;/th&gt; &lt;th width=&quot;&quot;&gt;员工工号&lt;/th&gt; &lt;th width=&quot;&quot;&gt;员工姓名&lt;/th&gt; &lt;th width=&quot;&quot;&gt;手机号&lt;/th&gt; &lt;th width=&quot;&quot;&gt;加入时间&lt;/th&gt; &lt;th width=&quot;&quot;&gt;所属部门&lt;/th&gt; &lt;th width=&quot;&quot;&gt;所属职位&lt;/th&gt; &lt;th width=&quot;&quot;&gt;是否为管理员&lt;/th&gt; &lt;th width=&quot;&quot;&gt;工作状态&lt;/th&gt; &lt;th width=&quot;&quot;&gt;操作&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr class=&quot;text-c&quot; th:each=&quot;item:$&#123;lists&#125;&quot;&gt; &lt;td&gt;&lt;input type=&quot;checkbox&quot; th:attr=&quot;value=$&#123;item.empId&#125;&quot; name=&quot;subCheck&quot; /&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;itemStat.count&#125;&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;item.empNum&#125;&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;item.empName&#125;&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;item.phone&#125;&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;#dates.format(item.createTime,&apos;yyyy-MM-dd&apos;)&#125;&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;item.deptName&#125;&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;item.jobName&#125;&quot;&gt;&lt;/td&gt; &lt;td class=&quot;flag&quot; th:attr=&quot;value=$&#123;item.flag&#125;&quot; th:text=&quot;$&#123;item.roleName&#125;==null?&apos;暂未分配&apos;:$&#123;item.roleName&#125;&quot;&gt;&lt;/td&gt; &lt;th:block th:if=&quot;$&#123;item.eStatus&#125;==1&quot;&gt; &lt;td class=&quot;td-status&quot;&gt;&lt;span class=&quot;label label-success radius&quot;&gt;正常&lt;/span&gt;&lt;/td&gt; &lt;/th:block&gt; &lt;th:block th:if=&quot;$&#123;item.eStatus&#125;==0&quot;&gt; &lt;td class=&quot;td-status&quot;&gt;&lt;span class=&quot;label radius&quot;&gt;异常&lt;/span&gt;&lt;/td&gt; &lt;/th:block&gt; &lt;td class=&quot;td-manage&quot; th:switch=&quot;$&#123;item.eStatus&#125;&quot;&gt; &lt;span th:case=&quot;1&quot;&gt; &lt;a style=&quot;text-decoration:none&quot; th:onClick=&quot;&apos;javascript:emp_stop(this,\&apos;&apos;+$&#123;item.empId&#125;+&apos;\&apos;)&apos;&quot; href=&quot;javascript:;&quot; title=&quot;异常&quot;&gt;&lt;i class=&quot;Hui-iconfont&quot;&gt;&amp;#xe631;&lt;/i&gt;&lt;/a&gt; &lt;/span&gt; &lt;span th:case=&quot;0&quot;&gt;&lt;a style=&quot;text-decoration:none&quot; th:onClick=&quot;&apos;javascript:emp_start(this,\&apos;&apos;+$&#123;item.empId&#125;+&apos;\&apos;)&apos;&quot; href=&quot;javascript:;&quot; title=&quot;正常&quot;&gt;&lt;i class=&quot;Hui-iconfont&quot;&gt;&amp;#xe615;&lt;/i&gt;&lt;/a&gt; &lt;/span&gt; &lt;a title=&quot;详情&quot; href=&quot;javascript:;&quot; th:onclick=&quot;&apos;javascript:emp_show(\&apos;&apos;+$&#123;item.empId&#125;+&apos;\&apos;)&apos;&quot; class=&quot;ml-5&quot; style=&quot;text-decoration:none&quot;&gt;&lt;i class=&quot;Hui-iconfont&quot;&gt;&amp;#xe665;&lt;/i&gt;&lt;/a&gt; &lt;a title=&quot;编辑&quot; href=&quot;javascript:;&quot; th:onclick=&quot;&apos;javascript:layer_update(this,\&apos;&apos;+$&#123;item.empId&#125;+&apos;\&apos;)&apos;&quot; class=&quot;ml-5&quot; style=&quot;text-decoration:none&quot;&gt;&lt;i class=&quot;Hui-iconfont&quot;&gt;&amp;#xe6df;&lt;/i&gt; &lt;/a&gt; &lt;a title=&quot;删除&quot; href=&quot;javascript:;&quot; th:onclick=&quot;&apos;javascript:emp_del(this, \&apos;&apos;+$&#123;item.empId&#125;+&apos;\&apos;)&apos;&quot; class=&quot;ml-5&quot; style=&quot;text-decoration:none&quot;&gt;&lt;i class=&quot;Hui-iconfont&quot;&gt;&amp;#xe6e2;&lt;/i&gt;&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &emsp;&emsp;数据表格的代码如上所示，勾选框采用的是input框，主要是用name=”subCheck”做标识。 2.判断是否选中了数据&emsp;&emsp;当我们点击了批量删除按钮之后，首先应该判断是否选中的数据，选中了之后才能进行下一步操作，没有选中数据则不进行下一步操作，并给出相应操作的提示。12345var checkNum=$(&quot;input[name=&apos;subCheck&apos;]:checked&quot;).length; if (checkNum==0)&#123; layerOpen(&quot;请至少选择一项&quot;); return; &#125; &emsp;&emsp;在这里，layerOpen是我自己封装的一个方法。功能特别简单，主要就是一个弹窗，弹出自定义的输出内容。代码如下：12345678910111213function layerOpen(msg) &#123; var index = layer.open(&#123; skin: &apos;layui-layer-molv&apos;, //样式类名 content: msg, btn: [&apos;确定&apos;], shade: 0.4, shadeClose: true, title: [&apos;错误信息&apos;, &apos;text-align:center; color: red&apos;], yes: function () &#123; layer.close(index); &#125; &#125;)&#125; 3.遍历所有的勾选框12345678910111213141516171819//批量选择 layer.confirm(&apos;确定要删除吗？&apos;, function (index) &#123; //获取所有选中的checked框 var option = $(&quot;:checked&quot;); var checkedId = &quot;&quot;; var flag=true; //拼接除全选框外所有选中的id for (var i=0, len = option.length; i &lt; len; i++)&#123; if (flag)&#123; if (option[i].id == &apos;subCheck&apos;)&#123; flag = true; &#125;else &#123; flag = false; checkedId += option[i].value; &#125; &#125;else &#123; checkedId += &quot;,&quot; +option[i].value &#125; &#125; &emsp;&emsp;先弹出一个确认框，当点击确认时才进行下一步的操作，否则直接退出。遍历当前页面上的每一个勾选框，遇到第一个勾选框选中时，在checkedId中存放这个勾选框的value值，也就是数据的UUID值，刚好这个值就是我们后台需要的，然后将定义的标识符flag定为false。之后继续遍历，遇到第二个勾选框被勾选时，记录数据的UUID,同时加一个”,”进行分隔。 4.将选中的数据UUID通过ajax传到后台123456789101112131415161718$.ajax(&#123; type: &quot;post&quot;, url: &quot;/permission/user/batchDelete&quot;, dataType: &quot;json&quot;, data: &#123;&quot;checkedId&quot;:checkedId&#125;, success: function (result) &#123; if (result.code == 0)&#123; layer.msg(result.data, &#123;icon: 6, time: 2000&#125;, function () &#123; retrieve(); &#125;) &#125;else&#123; layer.msg(result.data, &#123;icon: 5,time: 2000&#125;); &#125; &#125;, error: function (reslut) &#123; layer.msg(reslut.data, &#123;icon: 5, time: 2000&#125;); &#125; &#125;) 5.在后台对数据库数据进行操作12345678910111213141516//批量删除员工信息@PostMapping(value = &quot;/batchDelete&quot;)public void batchDelete(String empId)&#123; String[] empArrays=empId.split(&quot;,&quot;); List&lt;String&gt; list=Arrays.asList(empArrays); for (String id:list)&#123; Staff staff=empService.getEmpByEmpId(id); if (staff.isFlag())&#123; ResponseUtils.writeErrorResponse(request,response,&quot;选中的员工包括管理员，无法删除&quot;); throw new MyException(&quot;选中的员工信息包括管理员，无法删除&quot;); &#125; &#125; empService.batchDelete(list); ResponseUtils.writeSuccessReponse(request,response,&quot;批量删除员工信息成功&quot;);&#125; &emsp;&emsp;因为后台传过来的是一个字符串，所以我们首先将字符串切割开来放到一个数组里面，最后将数组转化为list集合，直接传递给mybatis完成删除操作即可。1234567891011121314&lt;delete id=&quot;batchDelete&quot; parameterType=&quot;java.util.List&quot;&gt;DELETE e.*, em.*, u.*, ur.*FROM t_emp eLEFT JOIN t_emp_param emON e.EMP_ID=em.EMP_IDLEFT JOIN t_user uON e.EMP_ID = u.USER_IDLEFT JOIN t_user_role urON u.USER_ID = ur.USER_IDWHERE e.EMP_ID IN&lt;foreach collection=&quot;list&quot; item=&quot;item&quot; open=&quot;(&quot; close=&quot;)&quot; separator=&quot;,&quot;&gt; #&#123;item&#125;&lt;/foreach&gt;&lt;/delete&gt; &emsp;&emsp;后台的操作比较简单，但是因为涉及到多张表关联，在这里我用到的是将多张表关联在一起然后匹配字段一起删除，比起级联删除，这样对资源池的消耗比较小。 6.对页面进行刷新，重新加载数据库中的数据12345678910/** * 刷新数据 */function reload() &#123; var data=&#123; pageNo: laypage_curr || 1, pageSize: laypage_limit || 10 &#125;; common.getData(&apos;post&apos;,&apos;/emp/retrieve&apos;,data,&apos;html&apos;,$(&quot;#page_data&quot;));&#125; &emsp;&emsp;以上操作即可实现数据的批量删除，操作比较简单，主要是为了记录下这个过程。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot 配置热部署]]></title>
    <url>%2F2018%2F03%2F28%2Fspring%20boot%E9%85%8D%E7%BD%AE%E7%83%AD%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[什么是热部署？&emsp;&emsp;热部署，就是在应用正在运行的时候升级软件，却不需要重新启动应用。在开发过程中，热部署对我们的开发速度有很大的帮助。例如在我们修改Bug的时候对Jsp或者Java类进行了修改在不重新启动WEB服务器就能让修改生效,配置文件除外。 怎么样进行热部署如何在idea中设置Tomcat热部署1.首先打开idea，点击右上角的下拉框，选中Edit Configurations,如下图： 2.点击对话框左上角的加号，选择Tomcat Server，再选择Local子菜单 3.选择Deployment选项卡，对需要部署的项目文件做设置，点击加号选择Artifact，然后选择war exploded方式，这种方式是以文件夹方式部署的，而war是以war包的方式，exploded方式支持热部署，注意一定要选择exploded方式，否则无法实现热部署。 4.然后回到Server选项卡，设置On Update action和On frame detectivation选项，都设置为Update classes and resources，表示classes文件和资源文件都更新 5.如果只设置On Update action选项，则需要每次自己手动点击更新，设置了On frame detectivation，会监测窗口，idea窗口发生切换则自动更新文件在运行模式下，Java文件更新不会立即生效，可以选择debug模式运行。 spring boot热部署配置spring boot致力于快速应用开发领域，内置了很多的组件，让我们摆脱了spring MVC下冗余的配置，使我们的开发变得更加的便捷快速。spring boot在自动嵌入了Tomcat，无需部署war文件，便可使项目快速运行起来，因此spring boot的热部署也与Tomcat的热部署不一样。spring boot的热部署是使用devtools模块。devtools模块，是为开发者服务的一个模块。主要的功能就是代码修改后一般在5秒之内就会自动重新加载至服务器，相当于restart成功。 原理分析 在发现代码有更改之后，自动重新启动应用，但是其速度比手动停止后再启动还要快些，更快这里指的不是节省出来的手工操作的时间。 一个Base ClassLoader加载器，用于加载不会改变的第三方依赖的jar； 另一个Restart ClassLoader加载器，用于加载自己编写的类； 执行流程：当应用重启后，原先的Restart ClassLoader被丢掉、重新new一个Restart ClassLoader来加载这些修改过的东西，而Base ClassLoader却没有变化。这就是devtools重启速度快的原因。 如何实现热部署 1.修改项目的pom.xml文件在依赖中加入:123456&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;version&gt;1.5.7.RELEASE&lt;/version&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 在构建中加入:12345678&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;addResources&gt;true&lt;/addResources&gt; &lt;/configuration&gt;&lt;/plugin&gt; 2.修改设置在idea中，还需要到设置里将project automatically勾选上；File-&gt;Setting，然后搜索“compiler” 将右侧project automatically勾上。 3.修改IDE配置使用ctrl+shift+a 快捷键搜索Registry，选择选择搜索出来的第一个，进入后找到“compiler.automake.allow.when.app.running”，勾上开启此功能即可。 4.应用热部署重新启动项目即可实现热部署，改动任意代码会立即生效，不用再每次重新启动项目]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot的配置文件application.properties详解]]></title>
    <url>%2F2018%2F03%2F28%2Fspring%20boot%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6application.properties%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;spring boot 设计之初的目的就是用来简化spring 应用的初始化搭建以及开发方式，使我们不用遵循固定的样本式配置，简化了开发过程。 但是我们在开发的过程中，却有些用法不得不配置，spring boot也给出了解决的办法，那就是配置全部都写在.properties或者.yml文件中。此博客正是记录.properties文件中的一些常用配置。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370# =================================================================== # COMMON SPRING BOOT PROPERTIES # # This sample file is provided as a guideline. Do NOT copy it in its # entirety to your own application. ^^^ # =================================================================== # ---------------------------------------- # CORE PROPERTIES # ---------------------------------------- # SPRING CONFIG (ConfigFileApplicationListener) spring.config.name= # config file name (default to &apos;application&apos;) spring.config.location= # location of config file # PROFILES spring.profiles= # comma list of active profiles # APPLICATION SETTINGS (SpringApplication) spring.main.sources= spring.main.web-environment= # detect by default spring.main.show-banner=true spring.main....= # see class for all properties # LOGGING logging.path=/var/logs logging.file=myapp.log logging.config= # IDENTITY (ContextIdApplicationContextInitializer) spring.application.name= spring.application.index= # EMBEDDED SERVER CONFIGURATION (ServerProperties) server.port=8080 server.address= # bind to a specific NIC server.session-timeout= # session timeout in seconds server.context-path= # the context path, defaults to &apos;/&apos; server.servlet-path= # the servlet path, defaults to &apos;/&apos; server.tomcat.access-log-pattern= # log pattern of the access log server.tomcat.access-log-enabled=false # is access logging enabled server.tomcat.protocol-header=x-forwarded-proto # ssl forward headers server.tomcat.remote-ip-header=x-forwarded-for server.tomcat.basedir=/tmp # base dir (usually not needed, defaults to tmp) server.tomcat.background-processor-delay=30; # in seconds server.tomcat.max-threads = 0 # number of threads in protocol handler server.tomcat.uri-encoding = UTF-8 # character encoding to use for URL decoding # SPRING MVC (HttpMapperProperties) http.mappers.json-pretty-print=false # pretty print JSON http.mappers.json-sort-keys=false # sort keys spring.mvc.locale= # set fixed locale, e.g. en_UK spring.mvc.date-format= # set fixed date format, e.g. dd/MM/yyyy spring.mvc.message-codes-resolver-format= # PREFIX_ERROR_CODE / POSTFIX_ERROR_CODE spring.view.prefix= # MVC view prefix spring.view.suffix= # ... and suffix spring.resources.cache-period= # cache timeouts in headers sent to browser spring.resources.add-mappings=true # if default mappings should be added # THYMELEAF (ThymeleafAutoConfiguration) spring.thymeleaf.prefix=classpath:/templates/ spring.thymeleaf.suffix=.html spring.thymeleaf.mode=HTML5 spring.thymeleaf.encoding=UTF-8 spring.thymeleaf.content-type=text/html # ;charset=&lt;encoding&gt; is added spring.thymeleaf.cache=true # set to false for hot refresh # FREEMARKER (FreeMarkerAutoConfiguration) spring.freemarker.allowRequestOverride=false spring.freemarker.allowSessionOverride=false spring.freemarker.cache=true spring.freemarker.checkTemplateLocation=true spring.freemarker.contentType=text/html spring.freemarker.exposeRequestAttributes=false spring.freemarker.exposeSessionAttributes=false spring.freemarker.exposeSpringMacroHelpers=false spring.freemarker.prefix= spring.freemarker.requestContextAttribute= spring.freemarker.settings.*= spring.freemarker.suffix=.ftl spring.freemarker.templateEncoding=UTF-8 spring.freemarker.templateLoaderPath=classpath:/templates/ spring.freemarker.viewNames= # whitelist of view names that can be resolved # GROOVY TEMPLATES (GroovyTemplateAutoConfiguration) spring.groovy.template.allowRequestOverride=false spring.groovy.template.allowSessionOverride=false spring.groovy.template.cache=true spring.groovy.template.configuration.*= # See Groovy&apos;s TemplateConfiguration spring.groovy.template.contentType=text/html spring.groovy.template.prefix=classpath:/templates/ spring.groovy.template.suffix=.tpl spring.groovy.template.templateEncoding=UTF-8 spring.groovy.template.viewNames= # whitelist of view names that can be resolved # VELOCITY TEMPLATES (VelocityAutoConfiguration) spring.velocity.allowRequestOverride=false spring.velocity.allowSessionOverride=false spring.velocity.cache=true spring.velocity.checkTemplateLocation=true spring.velocity.contentType=text/html spring.velocity.dateToolAttribute= spring.velocity.exposeRequestAttributes=false spring.velocity.exposeSessionAttributes=false spring.velocity.exposeSpringMacroHelpers=false spring.velocity.numberToolAttribute= spring.velocity.prefix= spring.velocity.properties.*= spring.velocity.requestContextAttribute= spring.velocity.resourceLoaderPath=classpath:/templates/ spring.velocity.suffix=.vm spring.velocity.templateEncoding=UTF-8 spring.velocity.viewNames= # whitelist of view names that can be resolved # INTERNATIONALIZATION (MessageSourceAutoConfiguration) spring.messages.basename=messages spring.messages.cacheSeconds=-1 spring.messages.encoding=UTF-8 # SECURITY (SecurityProperties) security.user.name=user # login username security.user.password= # login password security.user.role=USER # role assigned to the user security.require-ssl=false # advanced settings ... security.enable-csrf=false security.basic.enabled=true security.basic.realm=Spring security.basic.path= # /** security.headers.xss=false security.headers.cache=false security.headers.frame=false security.headers.contentType=false security.headers.hsts=all # none / domain / all security.sessions=stateless # always / never / if_required / stateless security.ignored=false # DATASOURCE (DataSourceAutoConfiguration &amp; DataSourceProperties) spring.datasource.name= # name of the data source spring.datasource.initialize=true # populate using data.sql spring.datasource.schema= # a schema (DDL) script resource reference spring.datasource.data= # a data (DML) script resource reference spring.datasource.platform= # the platform to use in the schema resource (schema-$&#123;platform&#125;.sql) spring.datasource.continueOnError=false # continue even if can&apos;t be initialized spring.datasource.separator=; # statement separator in SQL initialization scripts spring.datasource.driverClassName= # JDBC Settings... spring.datasource.url= spring.datasource.username= spring.datasource.password= spring.datasource.max-active=100 # Advanced configuration... spring.datasource.max-idle=8 spring.datasource.min-idle=8 spring.datasource.initial-size=10 spring.datasource.validation-query= spring.datasource.test-on-borrow=false spring.datasource.test-on-return=false spring.datasource.test-while-idle= spring.datasource.time-between-eviction-runs-millis= spring.datasource.min-evictable-idle-time-millis= spring.datasource.max-wait-millis= # MONGODB (MongoProperties) spring.data.mongodb.host= # the db host spring.data.mongodb.port=27017 # the connection port (defaults to 27107) spring.data.mongodb.uri=mongodb://localhost/test # connection URL spring.data.mongo.repositories.enabled=true # if spring data repository support is enabled # JPA (JpaBaseConfiguration, HibernateJpaAutoConfiguration) spring.jpa.properties.*= # properties to set on the JPA connection spring.jpa.openInView=true spring.jpa.show-sql=true spring.jpa.database-platform= spring.jpa.database= spring.jpa.generate-ddl=false # ignored by Hibernate, might be useful for other vendors spring.jpa.hibernate.naming-strategy= # naming classname spring.jpa.hibernate.ddl-auto= # defaults to create-drop for embedded dbs spring.data.jpa.repositories.enabled=true # if spring data repository support is enabled # SOLR (SolrProperties&#125;) spring.data.solr.host=http://127.0.0.1:8983/solr spring.data.solr.zkHost= spring.data.solr.repositories.enabled=true # if spring data repository support is enabled # ELASTICSEARCH (ElasticsearchProperties&#125;) spring.data.elasticsearch.cluster-name= # The cluster name (defaults to elasticsearch) spring.data.elasticsearch.cluster-nodes= # The address(es) of the server node (comma-separated; if not specified starts a client node) spring.data.elasticsearch.local=true # if local mode should be used with client nodes spring.data.elasticsearch.repositories.enabled=true # if spring data repository support is enabled # FLYWAY (FlywayProperties) flyway.locations=classpath:db/migrations # locations of migrations scripts flyway.schemas= # schemas to update flyway.initVersion= 1 # version to start migration flyway.prefix=V flyway.suffix=.sql flyway.enabled=true flyway.url= # JDBC url if you want Flyway to create its own DataSource flyway.user= # JDBC username if you want Flyway to create its own DataSource flyway.password= # JDBC password if you want Flyway to create its own DataSource # LIQUIBASE (LiquibaseProperties) liquibase.change-log=classpath:/db/changelog/db.changelog-master.yaml liquibase.contexts= # runtime contexts to use liquibase.default-schema= # default database schema to use liquibase.drop-first=false liquibase.enabled=true # JMX spring.jmx.enabled=true # Expose MBeans from Spring # RABBIT (RabbitProperties) spring.rabbitmq.host= # connection host spring.rabbitmq.port= # connection port spring.rabbitmq.addresses= # connection addresses (e.g. myhost:9999,otherhost:1111) spring.rabbitmq.username= # login user spring.rabbitmq.password= # login password spring.rabbitmq.virtualhost= spring.rabbitmq.dynamic= # REDIS (RedisProperties) spring.redis.host=localhost # server host spring.redis.password= # server password spring.redis.port=6379 # connection port spring.redis.pool.max-idle=8 # pool settings ... spring.redis.pool.min-idle=0 spring.redis.pool.max-active=8 spring.redis.pool.max-wait=-1 # ACTIVEMQ (ActiveMQProperties) spring.activemq.broker-url=tcp://localhost:61616 # connection URL spring.activemq.user= spring.activemq.password= spring.activemq.in-memory=true # broker kind to create if no broker-url is specified spring.activemq.pooled=false # HornetQ (HornetQProperties) spring.hornetq.mode= # connection mode (native, embedded) spring.hornetq.host=localhost # hornetQ host (native mode) spring.hornetq.port=5445 # hornetQ port (native mode) spring.hornetq.embedded.enabled=true # if the embedded server is enabled (needs hornetq-jms-server.jar) spring.hornetq.embedded.serverId= # auto-generated id of the embedded server (integer) spring.hornetq.embedded.persistent=false # message persistence spring.hornetq.embedded.data-directory= # location of data content (when persistence is enabled) spring.hornetq.embedded.queues= # comma separate queues to create on startup spring.hornetq.embedded.topics= # comma separate topics to create on startup spring.hornetq.embedded.cluster-password= # customer password (randomly generated by default) # JMS (JmsProperties) spring.jms.pub-sub-domain= # false for queue (default), true for topic # SPRING BATCH (BatchDatabaseInitializer) spring.batch.job.names=job1,job2 spring.batch.job.enabled=true spring.batch.initializer.enabled=true spring.batch.schema= # batch schema to load # AOP spring.aop.auto= spring.aop.proxy-target-class= # FILE ENCODING (FileEncodingApplicationListener) spring.mandatory-file-encoding=false # SPRING SOCIAL (SocialWebAutoConfiguration) spring.social.auto-connection-views=true # Set to true for default connection views or false if you provide your own # SPRING SOCIAL FACEBOOK (FacebookAutoConfiguration) spring.social.facebook.app-id= # your application&apos;s Facebook App ID spring.social.facebook.app-secret= # your application&apos;s Facebook App Secret # SPRING SOCIAL LINKEDIN (LinkedInAutoConfiguration) spring.social.linkedin.app-id= # your application&apos;s LinkedIn App ID spring.social.linkedin.app-secret= # your application&apos;s LinkedIn App Secret # SPRING SOCIAL TWITTER (TwitterAutoConfiguration) spring.social.twitter.app-id= # your application&apos;s Twitter App ID spring.social.twitter.app-secret= # your application&apos;s Twitter App Secret # SPRING MOBILE SITE PREFERENCE (SitePreferenceAutoConfiguration) spring.mobile.sitepreference.enabled=true # enabled by default # SPRING MOBILE DEVICE VIEWS (DeviceDelegatingViewResolverAutoConfiguration) spring.mobile.devicedelegatingviewresolver.enabled=true # disabled by default spring.mobile.devicedelegatingviewresolver.normalPrefix= spring.mobile.devicedelegatingviewresolver.normalSuffix= spring.mobile.devicedelegatingviewresolver.mobilePrefix=mobile/ spring.mobile.devicedelegatingviewresolver.mobileSuffix= spring.mobile.devicedelegatingviewresolver.tabletPrefix=tablet/ spring.mobile.devicedelegatingviewresolver.tabletSuffix= # ---------------------------------------- # ACTUATOR PROPERTIES # ---------------------------------------- # MANAGEMENT HTTP SERVER (ManagementServerProperties) management.port= # defaults to &apos;server.port&apos; management.address= # bind to a specific NIC management.contextPath= # default to &apos;/&apos; # ENDPOINTS (AbstractEndpoint subclasses) endpoints.autoconfig.id=autoconfig endpoints.autoconfig.sensitive=true endpoints.autoconfig.enabled=true endpoints.beans.id=beans endpoints.beans.sensitive=true endpoints.beans.enabled=true endpoints.configprops.id=configprops endpoints.configprops.sensitive=true endpoints.configprops.enabled=true endpoints.configprops.keys-to-sanitize=password,secret endpoints.dump.id=dump endpoints.dump.sensitive=true endpoints.dump.enabled=true endpoints.env.id=env endpoints.env.sensitive=true endpoints.env.enabled=true endpoints.health.id=health endpoints.health.sensitive=false endpoints.health.enabled=true endpoints.info.id=info endpoints.info.sensitive=false endpoints.info.enabled=true endpoints.metrics.id=metrics endpoints.metrics.sensitive=true endpoints.metrics.enabled=true endpoints.shutdown.id=shutdown endpoints.shutdown.sensitive=true endpoints.shutdown.enabled=false endpoints.trace.id=trace endpoints.trace.sensitive=true endpoints.trace.enabled=true # MVC ONLY ENDPOINTS endpoints.jolokia.path=jolokia endpoints.jolokia.sensitive=true endpoints.jolokia.enabled=true # when using Jolokia endpoints.error.path=/error # JMX ENDPOINT (EndpointMBeanExportProperties) endpoints.jmx.enabled=true endpoints.jmx.domain= # the JMX domain, defaults to &apos;org.springboot&apos; endpoints.jmx.unique-names=false endpoints.jmx.enabled=true endpoints.jmx.staticNames= # JOLOKIA (JolokiaProperties) jolokia.config.*= # See Jolokia manual # REMOTE SHELL shell.auth=simple # jaas, key, simple, spring shell.command-refresh-interval=-1 shell.command-path-pattern= # classpath*:/commands/**, classpath*:/crash/commands/** shell.config-path-patterns= # classpath*:/crash/* shell.disabled-plugins=false # don&apos;t expose plugins shell.ssh.enabled= # ssh settings ... shell.ssh.keyPath= shell.ssh.port= shell.telnet.enabled= # telnet settings ... shell.telnet.port= shell.auth.jaas.domain= # authentication settings ... shell.auth.key.path= shell.auth.simple.user.name= shell.auth.simple.user.password= shell.auth.spring.roles= # GIT INFO spring.git.properties= # resource ref to generated git info properties file]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA中使用mybatis generator逆向工程生成代码]]></title>
    <url>%2F2018%2F03%2F28%2FIDEA%E4%B8%AD%E4%BD%BF%E7%94%A8mybatis%20generator%E9%80%86%E5%90%91%E5%B7%A5%E7%A8%8B%E7%94%9F%E6%88%90%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;本文介绍下如何在idea中利用Maven工具逆向生成mybatis代码 1. 在maven中配置pom.xml文件在pom.xml的中加入如下插件： 12345678910&lt;!--mybatis 逆向工程--&gt;&lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;configuration&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt;&lt;/plugin&gt; 配置好maven插件后，进行下一步。 2. 添加逆向工程的配置文件在resources目录下新建一个generatorConfig.xml文件，然后将如下配置文件拷贝到上面建的文件中。maven的项目配置文件存放位置如下： generatorConfig.xml文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC &quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&quot;&gt;&lt;generatorConfiguration&gt; &lt;!--classPathEntry:数据库的JDBC驱动 --&gt; &lt;classPathEntry location=&quot;F:\.m2\repository\mysql\mysql-connector-java\5.1.34\mysql-connector-java-5.1.34.jar&quot; /&gt; &lt;!--&amp;lt;!&amp;ndash;导入属性配置&amp;ndash;&amp;gt;--&gt; &lt;!--&lt;properties resource=&quot;jdbc.properties&quot;&gt;&lt;/properties&gt;--&gt; &lt;context id=&quot;default&quot; targetRuntime=&quot;MyBatis3&quot;&gt; &lt;!-- optional，旨在创建class时，对注释进行控制 --&gt; &lt;commentGenerator&gt; &lt;property name=&quot;suppressDate&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;suppressAllComments&quot; value=&quot;true&quot;/&gt; &lt;/commentGenerator&gt; &lt;!--jdbc的数据库连接 --&gt; &lt;jdbcConnection driverClass=&quot;com.mysql.jdbc.Driver&quot; connectionURL=&quot;jdbc:mysql://localhost:3306/cms&quot; userId=&quot;root&quot; password=&quot;sky&quot;&gt; &lt;/jdbcConnection&gt; &lt;!-- 非必需，类型处理器，在数据库类型和java类型之间的转换控制--&gt; &lt;javaTypeResolver&gt; &lt;property name=&quot;forceBigDecimals&quot; value=&quot;false&quot;/&gt; &lt;/javaTypeResolver&gt; &lt;!-- Model模型生成器,用来生成含有主键key的类，记录类 以及查询Example类 targetPackage 指定生成的model生成所在的包名 targetProject 指定在该项目下所在的路径 --&gt; &lt;javaModelGenerator targetPackage=&quot;com.spring.cms.model.vo&quot; targetProject=&quot;src/main/java&quot;&gt; &lt;!-- 是否允许子包，即targetPackage.schemaName.tableName --&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot;/&gt; &lt;!-- 是否对model添加 构造函数 --&gt; &lt;property name=&quot;constructorBased&quot; value=&quot;true&quot;/&gt; &lt;!-- 是否对类CHAR类型的列的数据进行trim操作 --&gt; &lt;property name=&quot;trimStrings&quot; value=&quot;true&quot;/&gt; &lt;!-- 建立的Model对象是否 不可改变 即生成的Model对象不会有 setter方法，只有构造方法 --&gt; &lt;property name=&quot;immutable&quot; value=&quot;false&quot;/&gt; &lt;/javaModelGenerator&gt; &lt;!--Mapper映射文件生成所在的目录 为每一个数据库的表生成对应的SqlMap文件 --&gt; &lt;sqlMapGenerator targetPackage=&quot;mapper&quot; targetProject=&quot;src/main/resources&quot;&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot;/&gt; &lt;/sqlMapGenerator&gt; &lt;!-- 客户端代码，生成易于使用的针对Model对象和XML配置文件 的代码 type=&quot;ANNOTATEDMAPPER&quot;,生成Java Model 和基于注解的Mapper对象 type=&quot;MIXEDMAPPER&quot;,生成基于注解的Java Model 和相应的Mapper对象 type=&quot;XMLMAPPER&quot;,生成SQLMap XML文件和独立的Mapper接口 --&gt; &lt;javaClientGenerator targetPackage=&quot;com.spring.cms.dao&quot; targetProject=&quot;src/main/java&quot; type=&quot;XMLMAPPER&quot;&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt; &lt;/javaClientGenerator&gt; &lt;!-- 必须的（1...N） --&gt; &lt;!-- pojo 实体生成器 --&gt; &lt;!-- tableName:用于自动生成代码的数据库表；domainObjectName:对应于数据库表的javaBean类名 --&gt; &lt;!-- schema即为数据库名 可不写 --&gt; &lt;table tableName=&quot;cc_user&quot; domainObjectName=&quot;User&quot; enableCountByExample=&quot;false&quot; enableUpdateByExample=&quot;false&quot; enableDeleteByExample=&quot;false&quot; enableSelectByExample=&quot;false&quot; selectByExampleQueryId=&quot;false&quot;&gt; &lt;!-- 忽略字段 可选的（0 or 1） --&gt; &lt;!-- &lt;ignoreColumn column=&quot;is_use&quot; /&gt; --&gt; &lt;!--//无论字段是什么类型，生成的类属性都是varchar。 可选的（0 or 1） 测试无效 --&gt; &lt;!-- &lt;columnOverride column=&quot;city_code&quot; jdbcType=&quot;VARCHAR&quot; /&gt; --&gt; &lt;/table&gt; &lt;!-- 必须的（1...N） --&gt; &lt;!-- pojo 实体生成器 --&gt; &lt;!-- tableName:用于自动生成代码的数据库表；domainObjectName:对应于数据库表的javaBean类名 --&gt; &lt;!-- schema即为数据库名 可不写 --&gt; &lt;table tableName=&quot;cc_user_role&quot; domainObjectName=&quot;UserRole&quot; enableCountByExample=&quot;false&quot; enableUpdateByExample=&quot;false&quot; enableDeleteByExample=&quot;false&quot; enableSelectByExample=&quot;false&quot; selectByExampleQueryId=&quot;false&quot;&gt; &lt;!-- 忽略字段 可选的（0 or 1） --&gt; &lt;!-- &lt;ignoreColumn column=&quot;is_use&quot; /&gt; --&gt; &lt;!--//无论字段是什么类型，生成的类属性都是varchar。 可选的（0 or 1） 测试无效 --&gt; &lt;!-- &lt;columnOverride column=&quot;city_code&quot; jdbcType=&quot;VARCHAR&quot; /&gt; --&gt; &lt;/table&gt; &lt;!-- 必须的（1...N） --&gt; &lt;!-- pojo 实体生成器 --&gt; &lt;!-- tableName:用于自动生成代码的数据库表；domainObjectName:对应于数据库表的javaBean类名 --&gt; &lt;!-- schema即为数据库名 可不写 --&gt; &lt;table tableName=&quot;cc_role&quot; domainObjectName=&quot;Role&quot; enableCountByExample=&quot;false&quot; enableUpdateByExample=&quot;false&quot; enableDeleteByExample=&quot;false&quot; enableSelectByExample=&quot;false&quot; selectByExampleQueryId=&quot;false&quot;&gt; &lt;!-- 忽略字段 可选的（0 or 1） --&gt; &lt;!-- &lt;ignoreColumn column=&quot;is_use&quot; /&gt; --&gt; &lt;!--//无论字段是什么类型，生成的类属性都是varchar。 可选的（0 or 1） 测试无效 --&gt; &lt;!-- &lt;columnOverride column=&quot;city_code&quot; jdbcType=&quot;VARCHAR&quot; /&gt; --&gt; &lt;/table&gt; &lt;!-- 必须的（1...N） --&gt; &lt;!-- pojo 实体生成器 --&gt; &lt;!-- tableName:用于自动生成代码的数据库表；domainObjectName:对应于数据库表的javaBean类名 --&gt; &lt;!-- schema即为数据库名 可不写 --&gt; &lt;table tableName=&quot;cc_role_resource&quot; domainObjectName=&quot;RoleResource&quot; enableCountByExample=&quot;false&quot; enableUpdateByExample=&quot;false&quot; enableDeleteByExample=&quot;false&quot; enableSelectByExample=&quot;false&quot; selectByExampleQueryId=&quot;false&quot;&gt; &lt;!-- 忽略字段 可选的（0 or 1） --&gt; &lt;!-- &lt;ignoreColumn column=&quot;is_use&quot; /&gt; --&gt; &lt;!--//无论字段是什么类型，生成的类属性都是varchar。 可选的（0 or 1） 测试无效 --&gt; &lt;!-- &lt;columnOverride column=&quot;city_code&quot; jdbcType=&quot;VARCHAR&quot; /&gt; --&gt; &lt;/table&gt; &lt;!-- 必须的（1...N） --&gt; &lt;!-- pojo 实体生成器 --&gt; &lt;!-- tableName:用于自动生成代码的数据库表；domainObjectName:对应于数据库表的javaBean类名 --&gt; &lt;!-- schema即为数据库名 可不写 --&gt; &lt;table tableName=&quot;cc_resource&quot; domainObjectName=&quot;Resource&quot; enableCountByExample=&quot;false&quot; enableUpdateByExample=&quot;false&quot; enableDeleteByExample=&quot;false&quot; enableSelectByExample=&quot;false&quot; selectByExampleQueryId=&quot;false&quot;&gt; &lt;!-- 忽略字段 可选的（0 or 1） --&gt; &lt;!-- &lt;ignoreColumn column=&quot;is_use&quot; /&gt; --&gt; &lt;!--//无论字段是什么类型，生成的类属性都是varchar。 可选的（0 or 1） 测试无效 --&gt; &lt;!-- &lt;columnOverride column=&quot;city_code&quot; jdbcType=&quot;VARCHAR&quot; /&gt; --&gt; &lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; jdbc.properties配置文件的代码如下： 12345678910driverClassName=com.mysql.jdbc.DrivervalidationQuery=SELECT 1jdbc_url=jdbc:mysql://localhost:3306/contentmanagersystem_db?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNulljdbc_username=rootjdbc_password=skyjdbc.mysql-master.initialSize=5jdbc.mysql-master.maxActive=5jdbc.mysql-master.maxIdle=5jdbc.mysql-master.minIdle=1jdbc.mysql-master.maxWait=6000 3. 在IDEA中利用插件生成代码选择IDEA右上角下拉框中的Edit Configurations,然后进入到配置页面，选择做上角的 + 号，如图： 选择maven，然后在Commond line栏填上如图命令 点击应用。最后点击启动按钮，即可自动生成代码。 生成成功！]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logback的使用和logback的配置]]></title>
    <url>%2F2018%2F03%2F17%2Flogback%E7%9A%84%E4%BD%BF%E7%94%A8%E5%92%8Clogback%E7%9A%84%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[一.logback的介绍&emsp;&emsp;Logback是由log4j创始人设计的另一个开源日志组件,官方网站：http://logback.qos.ch。它当前分为下面下个模块：&emsp;&emsp;logback-core：其它两个模块的基础模块&emsp;&emsp;它是log4j的一个改良版本，同时它完整实现了slf4j API使你可以很方便地更换成其它日志系统如log4j或JDK14 Logging&emsp;&emsp;访问模块与Servlet容器集成提供通过Http来访问日志的功能 二.logback取代log4j的理由：&emsp;&emsp;1、更快的实现：Logback的内核重写了，在一些关键执行路径上性能提升10倍以上。而且logback不仅性能提升了，初始化内存加载也更小了。&emsp;&emsp;2、非常充分的测试：Logback经过了几年，数不清小时的测试。Logback的测试完全不同级别的。&emsp;&emsp;3、Logback-classic非常自然实现了SLF4j：Logback-classic实现了SLF4j。在使用SLF4j中，你都感觉不到logback-classic。而且因为logback-classic非常自然地实现了slf4j ， 所 以切换到log4j或者其他，非常容易，只需要提供成另一个jar包就OK，根本不需要去动那些通过SLF4JAPI实现的代码。&emsp;&emsp;4、非常充分的文档 官方网站有两百多页的文档。&emsp;&emsp;5、自动重新加载配置文件，当配置文件修改了，Logback-classic能自动重新加载配置文件。扫描过程快且安全，它并不需要另外创建一个扫描线程。这个技术充分保证了应用程序能跑得很欢在JEE环境里面。&emsp;&emsp;6、Lilith是log事件的观察者，和log4j的chainsaw类似。而lilith还能处理大数量的log数据 。&emsp;&emsp;7、谨慎的模式和非常友好的恢复，在谨慎模式下，多个FileAppender实例跑在多个JVM下，能 够安全地写道同一个日志文件。RollingFileAppender会有些限制。Logback的FileAppender和它的子类包括 RollingFileAppender能够非常友好地从I/O异常中恢复。&emsp;&emsp;8、配置文件可以处理不同的情况，开发人员经常需要判断不同的Logback配置文件在不同的环境下（开发，测试，生产）。而这些配置文件仅仅只有一些很小的不同，可以通过,和来实现，这样一个配置文件就可以适应多个环境。&emsp;&emsp;9、Filters（过滤器）有些时候，需要诊断一个问题，需要打出日志。在log4j，只有降低日志级别，不过这样会打出大量的日志，会影响应用性能。在Logback，你可以继续 保持那个日志级别而除掉某种特殊情况，如alice这个用户登录，她的日志将打在DEBUG级别而其他用户可以继续打在WARN级别。要实现这个功能只需加4行XML配置。可以参考MDCFIlter 。&emsp;&emsp;10、SiftingAppender（一个非常多功能的Appender）：它可以用来分割日志文件根据任何一个给定的运行参数。如，SiftingAppender能够区别日志事件跟进用户的Session，然后每个用户会有一个日志文件。&emsp;&emsp;11、自动压缩已经打出来的log：RollingFileAppender在产生新文件的时候，会自动压缩已经打出来的日志文件。压缩是个异步过程，所以甚至对于大的日志文件，在压缩过程中应用不会受任何影响。&emsp;&emsp;12、堆栈树带有包版本：Logback在打出堆栈树日志时，会带上包的数据。&emsp;&emsp;13、自动去除旧的日志文件：通过设置TimeBasedRollingPolicy或者SizeAndTimeBasedFNATP的maxHistory属性，你可以控制已经产生日志文件的最大数量。如果设置maxHistory 12，那那些log文件超过12个月的都会被自动移除。 三、logback的配置介绍&emsp;&emsp;1、Logger、appender及layout&emsp;&emsp;Logger作为日志的记录器，把它关联到应用的对应的context上后，主要用于存放日志对象，也可以定义日志类型、级别。&emsp;&emsp;Appender主要用于指定日志输出的目的地，目的地可以是控制台、文件、远程套接字服务器、 MySQL、PostreSQL、 Oracle和其他数据库、 JMS和远程UNIX Syslog守护进程等。&emsp;&emsp;Layout 负责把事件转换成字符串，格式化的日志信息的输出。&emsp;&emsp;2、logger context&emsp;&emsp;各个logger 都被关联到一个 LoggerContext，LoggerContext负责制造logger，也负责以树结构排列各logger。其他所有logger也通过org.slf4j.LoggerFactory 类的静态方法getLogger取得。 getLogger方法以 logger名称为参数。用同一名字调用LoggerFactory.getLogger 方法所得到的永远都是同一个logger对象的引用。&emsp;&emsp;3、有效级别及级别的继承&emsp;&emsp;Logger 可以被分配级别。级别包括：TRACE、DEBUG、INFO、WARN 和 ERROR，定义于ch.qos.logback.classic.Level类。如果 logger没有被分配级别，那么它将从有被分配级别的最近的祖先那里继承级别。root logger 默认级别是 DEBUG。&emsp;&emsp;4、打印方法与基本的选择规则&emsp;&emsp;打印方法决定记录请求的级别。例如，如果 L 是一个 logger 实例，那么，语句 L.info(“..”)是一条级别为 INFO的记录语句。记录请求的级别在高于或等于其 logger 的有效级别时被称为被启用，否则，称为被禁用。记录请求级别为 p，其 logger的有效级别为 q，只有则当 p&gt;=q时，该请求才会被执行。该规则是 logback 的核心。级别排序为： TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR 四、logback的默认配置&emsp;&emsp;如果配置文件 logback-test.xml 和 logback.xml 都不存在，那么 logback 默认地会调用BasicConfigurator ，创建一个最小化配置。最小化配置由一个关联到根 logger 的ConsoleAppender 组成。输出用模式为%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n 的 PatternLayoutEncoder 进行格式化。root logger 默认级别是 DEBUG。&emsp;&emsp;1、Logback的配置文件&emsp;&emsp;Logback 配置文件的语法非常灵活。正因为灵活，所以无法用 DTD 或 XML schema 进行定义。尽管如此，可以这样描述配置文件的基本结构：以开头，后面有零个或多个元素，有零个或多个元素，有最多一个元素。&emsp;&emsp;2、Logback默认配置步骤&emsp;&emsp;&nbsp;(1). 尝试在 classpath下查找文件logback-test.xml；&emsp;&emsp;&nbsp;(2). 如果文件不存在，则查找文件logback.xml；&emsp;&emsp;&nbsp;(3). 如果两个文件都不存在，logback用BasicConfigurator自动对自己进行配置，这会导致记录输出到控制台。 五、logback.xml常用配置详解&emsp;&emsp;1、根节点，包含下面三个属性：&emsp;&emsp;scan: 当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。&emsp;&emsp;scanPeriod: 设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。&emsp;&emsp;debug: 当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。例如: 123&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt; &lt;!--其他配置省略--&gt;&lt;/configuration&gt; &emsp;&emsp;2、子节点：用来设置上下文名称，每个logger都关联到logger上下文，默认上下文名称为default。但可以使用设置成其他名字，用于区分不同应用程序的记录。一旦设置，不能修改。例如： 1234&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt; &lt;contextName&gt;myAppName&lt;/contextName&gt; &lt;!--其他配置省略--&gt;&lt;/configuration&gt; &emsp;&emsp;3、子节点：用来定义变量值，它有两个属性name和value，通过定义的值会被插入到logger上下文中，可以使“${}”来使用变量。&emsp;&emsp;&emsp;name: 变量的名称&emsp;&emsp;&emsp;value: 的值时变量定义的值例如：12345&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt; &lt;property name=&quot;APP_Name&quot; value=&quot;myAppName&quot; /&gt; &lt;contextName&gt;$&#123;APP_Name&#125;&lt;/contextName&gt; &lt;!--其他配置省略--&gt;&lt;/configuration&gt; &emsp;&emsp;4、子节点：获取时间戳字符串，他有两个属性key和datePattern&emsp;&emsp;key: 标识此 的名字；&emsp;&emsp;datePattern: 设置将当前时间（解析配置文件的时间）转换为字符串的模式，遵循java.txt.SimpleDateFormat的格式。例如：12345&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt; &lt;timestamp key=&quot;bySecond&quot; datePattern=&quot;yyyyMMdd&apos;T&apos;HHmmss&quot;/&gt; &lt;contextName&gt;$&#123;bySecond&#125;&lt;/contextName&gt; &lt;!-- 其他配置省略--&gt;&lt;/configuration&gt; &emsp;&emsp;5、子节点：负责写日志的组件，它有两个必要属性name和class。name指定appender名称，class指定appender的全限定名 &emsp;&emsp;&emsp;5.1、ConsoleAppender 把日志输出到控制台，有以下子节点：12&lt;encoder&gt;：对日志进行格式化。（具体参数稍后讲解 ）&lt;target&gt;：字符串System.out(默认)或者System.err（区别不多说了） 例如：1234567891011&lt;configuration&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt;%-4relative [%thread] %-5level %logger&#123;35&#125; - %msg %n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;DEBUG&quot;&gt; &lt;appender-ref ref=&quot;STDOUT&quot; /&gt; &lt;/root&gt;&lt;/configuration&gt; &emsp;&emsp;上述配置表示把&gt;=DEBUG级别的日志都输出到控制台 &emsp;&emsp;&emsp;5.2、FileAppender：把日志添加到文件，有以下子节点：1234&lt;file&gt;：被写入的文件名，可以是相对目录，也可以是绝对目录，如果上级目录不存在会自动创建，没有默认值。&lt;append&gt;：如果是 true，日志被追加到文件结尾，如果是 false，清空现存文件，默认是true。&lt;encoder&gt;：对记录事件进行格式化。（具体参数稍后讲解 ）&lt;prudent&gt;：如果是 true，日志会被安全的写入文件，即使其他的FileAppender也在向此文件做写入操作，效率低，默认是 false。 例如：12345678910111213&lt;configuration&gt; &lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.FileAppender&quot;&gt; &lt;file&gt;testFile.log&lt;/file&gt; &lt;append&gt;true&lt;/append&gt; &lt;encoder&gt; &lt;pattern&gt;%-4relative [%thread] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;DEBUG&quot;&gt; &lt;appender-ref ref=&quot;FILE&quot; /&gt; &lt;/root&gt;&lt;/configuration&gt; &emsp;&emsp;上述配置表示把&gt;=DEBUG级别的日志都输出到testFile.log &emsp;&emsp;&emsp;5.3、RollingFileAppender：滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件。有以下子节点：1234567891011121314&lt;file&gt;：被写入的文件名，可以是相对目录，也可以是绝对目录，如果上级目录不存在会自动创建，没有默认值。&lt;append&gt;：如果是 true，日志被追加到文件结尾，如果是 false，清空现存文件，默认是true。 &lt;rollingPolicy&gt;:当发生滚动时，决定RollingFileAppender的行为，涉及文件移动和重命名。属性class定义具体的滚动策略类 class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;： 最常用的滚动策略，它根据时间来制定滚动策略，既负责滚动也负责出发滚动。有以下子节点：&lt;fileNamePattern&gt;：必要节点，包含文件名及“%d”转换符，“%d”可以包含一个java.text.SimpleDateFormat指定的时间格式，如：%d&#123;yyyy-MM&#125;。如果直接使用 %d，默认格式是 yyyy-MM-dd。RollingFileAppender的file字节点可有可无，通过设置file，可以为活动文件和归档文件指定不同位置，当前日志总是记录到file指定的文件（活动文件），活动文件的名字不会改变；如果没设置file，活动文件的名字会根据fileNamePattern 的值，每隔一段时间改变一次。“/”或者“\”会被当做目录分隔符。 &lt;maxHistory&gt;:可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件。假设设置每个月滚动，且&lt;maxHistory&gt;是6，则只保存最近6个月的文件，删除之前的旧文件。注意，删除旧文件是，那些为了归档而创建的目录也会被删除。 class=&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;： 查看当前活动文件的大小，如果超过指定大小会告知RollingFileAppender 触发当前活动文件滚动。只有一个节点:&lt;maxFileSize&gt;:这是活动文件的大小，默认值是10MB。&lt;prudent&gt;：当为true时，不支持FixedWindowRollingPolicy。支持TimeBasedRollingPolicy，但是有两个限制，1不支持也不允许文件压缩，2不能设置file属性，必须留空。 &lt;triggeringPolicy &gt;: 告知 RollingFileAppender 合适激活滚动。 class=&quot;ch.qos.logback.core.rolling.FixedWindowRollingPolicy&quot; 根据固定窗口算法重命名文件的滚动策略。有以下子节点：&lt;minIndex&gt;:窗口索引最小值&lt;maxIndex&gt;:窗口索引最大值，当用户指定的窗口过大时，会自动将窗口设置为12。&lt;fileNamePattern&gt;:必须包含“%i”例如，假设最小值和最大值分别为1和2，命名模式为 mylog%i.log,会产生归档文件mylog1.log和mylog2.log。还可以指定文件压缩选项，例如，mylog%i.log.gz 或者 没有log%i.log.zip 例如：12345678910111213141516171819202122232425262728293031323334353637&lt;configuration&gt; &lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt; fileNamePattern&gt;logFile.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%-4relative [%thread] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;DEBUG&quot;&gt; &lt;appender-ref ref=&quot;FILE&quot; /&gt; &lt;/root&gt;&lt;/configuration&gt;//上述配置表示每天生成一个日志文件，保存30天的日志文件。&lt;configuration&gt; &lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;file&gt;test.log&lt;/file&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.FixedWindowRollingPolicy&quot;&gt; &lt;fileNamePattern&gt; tests.%i.log.zip &lt;/fileNamePattern&gt; &lt;minIndex&gt;1&lt;/minIndex&gt; &lt;maxIndex&gt;3&lt;/maxIndex&gt; &lt;/rollingPolicy&gt; &lt;triggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;&gt; &lt;maxFileSize&gt;5MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%-4relative [%thread] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;DEBUG&quot;&gt; &lt;appender-ref ref=&quot;FILE&quot; /&gt; &lt;/root&gt;&lt;/configuration&gt; &emsp;&emsp;上述配置表示按照固定窗口模式生成日志文件，当文件大于20MB时，生成新的日志文件。窗口大小是1到3，当保存了3个归档文件后，将覆盖最早的日志。12&lt;encoder&gt;：对记录事件进行格式化。负责两件事，一是把日志信息转换成字节数组，二是把字节数组写入到输出流。PatternLayoutEncoder 是唯一有用的且默认的encoder ，有一个&lt;pattern&gt;节点，用来设置日志的输入格式。使用“%”加“转换符”方式，如果要输出“%”，则必须用“\”对“\%”进行转义。 &emsp;&emsp;&emsp;5.4、还有SocketAppender、SMTPAppender、DBAppender、SyslogAppender、SiftingAppender，并不常用，这里就不详解了。大家可以参考官方文档(http://logback.qos.ch/documentation.html)，还可以编写自己的Appender。 &emsp;&emsp;6、子节点：用来设置某一个包或具体的某一个类的日志打印级别、以及指定。仅有一个name属性，一个可选的level和一个可选的addtivity属性。可以包含零个或多个元素，标识这个appender将会添加到这个loger。&emsp;&emsp;name: 用来指定受此loger约束的某一个包或者具体的某一个类。&emsp;&emsp;level: 用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL和OFF，还有一个特俗值INHERITED或者同义词NULL，代表强制执行上级的级别。 如果未设置此属性，那么当前loger将会继承上级的级别。1addtivity: 是否向上级loger传递打印信息。默认是true。同&lt;loger&gt;一样，可以包含零个或多个&lt;appender-ref&gt;元素，标识这个appender将会添加到这个loger。 &emsp;&emsp;7、子节点:它也是元素，但是它是根loger,是所有的上级。只有一个level属性，因为name已经被命名为”root”,且已经是最上级了。 level: 用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL和OFF，不能设置为INHERITED或者同义词NULL。 默认是DEBUG。 六、常用loger配置123456789101112&lt;!-- show parameters for hibernate sql 专为 Hibernate 定制 --&gt;&lt;logger name=&quot;org.hibernate.type.descriptor.sql.BasicBinder&quot; level=&quot;TRACE&quot; /&gt;&lt;logger name=&quot;org.hibernate.type.descriptor.sql.BasicExtractor&quot; level=&quot;DEBUG&quot; /&gt;&lt;logger name=&quot;org.hibernate.SQL&quot; level=&quot;DEBUG&quot; /&gt;&lt;logger name=&quot;org.hibernate.engine.QueryParameters&quot; level=&quot;DEBUG&quot; /&gt;&lt;logger name=&quot;org.hibernate.engine.query.HQLQueryPlan&quot; level=&quot;DEBUG&quot; /&gt;&lt;!--myibatis log configure--&gt;&lt;logger name=&quot;com.apache.ibatis&quot; level=&quot;TRACE&quot;/&gt;&lt;logger name=&quot;java.sql.Connection&quot; level=&quot;DEBUG&quot;/&gt;&lt;logger name=&quot;java.sql.Statement&quot; level=&quot;DEBUG&quot;/&gt;&lt;logger name=&quot;java.sql.PreparedStatement&quot; level=&quot;DEBUG&quot;/&gt; 七、Demo&emsp;&emsp;1、添加依赖包logback使用需要和slf4j一起使用，所以总共需要添加依赖的包有slf4j-apilogback使用需要和slf4j一起使用，所以总共需要添加依赖的包有slf4j-api.jar，logback-core.jar，logback-classic.jar，logback-access.jar这个暂时用不到所以不添加依赖了，maven配置123456789101112131415161718192021222324&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;logback.version&gt;1.1.7&lt;/logback.version&gt; &lt;slf4j.version&gt;1.7.21&lt;/slf4j.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &emsp;&emsp;2、logback.xml配置12345678910111213141516171819202122232425262728293031323334&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration debug=&quot;false&quot;&gt;&lt;!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径--&gt;&lt;property name=&quot;LOG_HOME&quot; value=&quot;/home&quot; /&gt;&lt;!-- 控制台输出 --&gt;&lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;&lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;&lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt;&lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt;&lt;/encoder&gt;&lt;/appender&gt;&lt;!-- 按照每天生成日志文件 --&gt;&lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;&lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;&lt;!--日志文件输出的文件名--&gt;&lt;FileNamePattern&gt;$&#123;LOG_HOME&#125;/TestWeb.log.%d&#123;yyyy-MM-dd&#125;.log&lt;/FileNamePattern&gt;&lt;!--日志文件保留天数--&gt;&lt;MaxHistory&gt;30&lt;/MaxHistory&gt;&lt;/rollingPolicy&gt;&lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;&lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt;&lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt;&lt;/encoder&gt;&lt;!--日志文件最大的大小--&gt;&lt;triggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;&gt;&lt;MaxFileSize&gt;10MB&lt;/MaxFileSize&gt;&lt;/triggeringPolicy&gt;&lt;/appender&gt;&lt;!-- 日志输出级别 --&gt;&lt;root level=&quot;INFO&quot;&gt;&lt;appender-ref ref=&quot;STDOUT&quot; /&gt;&lt;/root&gt;&lt;/configuration&gt; &emsp;&emsp;3、java代码12345678910111213/** * Hello world! */ public class App &#123; private final static Logger logger = LoggerFactory.getLogger(App.class); public static void main(String[] args) &#123; logger.info(&quot;logback 成功了&quot;); logger.error(&quot;logback 成功了&quot;); logger.debug(&quot;logback 成功了&quot;); &#125; &#125; &emsp;&emsp;4、输出 八、总结&emsp;&emsp;logback的配置，需要配置输出源appender，打日志的loger（子节点）和root（根节点），实际上，它输出日志是从子节点开始，子节点如果有输出源直接输入，如果无，判断配置的addtivity，是否像上级传递，即是否向root传递，传递则采用root的输出源，否则不输出日志。]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Echarts使用ajax实现动态数据的加载]]></title>
    <url>%2F2018%2F03%2F14%2FEcharts%E4%BD%BF%E7%94%A8ajax%E5%AE%9E%E7%8E%B0%E5%8A%A8%E6%80%81%E6%95%B0%E6%8D%AE%E7%9A%84%E5%8A%A0%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;最近在做项目时，感觉dataTables表格使用的太多了，突发奇想为何不使用图表的方式来展示数据，经过网上一番教程的学习，成功的使用后台传输的数据实现了Echarts动态数据的加载。 &emsp;&emps;Echarts(3.x)官网实例的数据都是静态的，但是在实际项目中，我们往往会使用动态加载数据，但是官网里面给出的异步加载动态数据的教程非常模糊，让人有点摸不着头脑，所以写下这篇博客记录下使用Echarts动态加载数据的实例。&emsp;&emsp;一般的步骤分为以下几步: 1.客户端通过ajax发送请求。 2.服务端接收ajax请求，并作出相应的回应。 3.服务端生成json数据并返回给客户端。 4.客户端接收json数据后通过Echarts显示在页面上。 1.定义div块&emsp;&emsp;在页面中为Echarts定义一个div块，并且设置宽高，Echarts加载出来的图表就显示在div块中1&lt;div id=&quot;attend_list&quot; class=&quot;attend-list mt-40&quot; style=&quot;display: block&quot;&gt;&lt;/div&gt; 2.在Echarts官网选择样式官网地址,官网中有很多的实例，选择自己需要的下载对应的文件即可。 3.客户端通过ajax发送请求123456789101112131415161718192021222324252627282930313233343536373839404142434445464748var myChart = echarts.init(document.getElementById(&apos;attend_list&apos;));var dataShadow = [];option = null;var yMax = 8;var dateNum = []; //日期数组，用来放请求的日期var timeNum = []; //考勤时长，用来放用来的考勤时间var id;var variable ;var year;var month;$(function () &#123; //加载事件 var collection = $(&quot;.layui-btn&quot;); $.each(collection, function () &#123; $(this).addClass(&quot;start&quot;); &#125;); $(&quot;#month&quot;).addClass(&quot;end&quot;); var gather = $(&quot;.cut&quot;); $.each(gather, function () &#123; $(this).addClass(&quot;start&quot;); &#125;); $(&quot;#bar&quot;).addClass(&quot;end1&quot;); document.getElementById(&quot;pages&quot;).style.display = &quot;none&quot;; dateNum =[]; timeNum = []; $.ajax(&#123; type: &apos;post&apos;, //异步请求(同步请求将会锁住浏览器，用户必须等待其他的操作完成后才能进行其它的操作) url: &apos;/attend/data&apos;, dataType: &apos;json&apos;, success: function (result) &#123; var data = result.data; for (var i = 0, length = data.length; i &lt; length; i++) &#123; var array1 = data[i].attendDate.split(&quot;-&quot;); year = array1[0]; month = array1[1]; dateNum.push(array1[2]); timeNum.push(data[i].workHours); &#125; myChart.hideLoading(); //隐藏加载动画 //将Echarts表格信息抽取出来 loadTable(); &#125; &#125;);&#125;); &emsp;&emsp;先定义两个空的数组，然后将ajax返回的值填充到这两个空的数组中，最后用这两个数组中的值填充到Echarts图表中横纵坐标的值。 4.Echarts图表显示js123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103function loadTable() &#123; for (var i = 0; i &lt; timeNum.length; i++) &#123; dataShadow.push(yMax); &#125; myChart.on(&apos;click&apos;, function (params) &#123; console.log(params); var clickDate=params.name; console.log(clickDate); console.log(year); console.log(month); detailed(clickDate); &#125;); option=(&#123; title: &#123; left: &apos;center&apos;, text: &quot;考勤信息展示图&quot; &#125;, xAxis: &#123; name: &apos;日期&apos;, data: dateNum, axisLabel: &#123; inside: true, textStyle: &#123; color: &apos;#000000&apos; &#125; &#125;, axisTick: &#123; show: false &#125;, axisLine: &#123; show: false &#125;, z: 8 &#125;, yAxis: &#123; name: &apos;考勤时长/h&apos;, axisLine: &#123; show: false &#125;, axisTick: &#123; show: false &#125;, axisLabel: &#123; textStyle: &#123; color: &apos;#000000&apos; &#125; &#125; &#125;, dataZoom: [ &#123; type: &apos;inside&apos; &#125; ], series: [ &#123; // For shadow type: &apos;bar&apos;, itemStyle: &#123; normal: &#123;color: &apos;rgba(0,0,0,0.05)&apos;&#125; &#125;, barGap:&apos;-100%&apos;, barCategoryGap:&apos;40%&apos;, data: dataShadow, animation: false &#125;, &#123; type: &apos;bar&apos;, itemStyle: &#123; normal: &#123; color: new echarts.graphic.LinearGradient( 0, 0, 0, 1, [ &#123;offset: 0, color: &apos;#83bff6&apos;&#125;, &#123;offset: 0.5, color: &apos;#188df0&apos;&#125;, &#123;offset: 1, color: &apos;#188df0&apos;&#125; ] ) &#125;, emphasis: &#123; color: new echarts.graphic.LinearGradient( 0, 0, 0, 1, [ &#123;offset: 0, color: &apos;#2378f7&apos;&#125;, &#123;offset: 0.7, color: &apos;#2378f7&apos;&#125;, &#123;offset: 1, color: &apos;#83bff6&apos;&#125; ] ) &#125; &#125;, data: timeNum &#125; ] &#125;); myChart.hideLoading(); //隐藏加载动画 if (option &amp;&amp; typeof option === &quot;object&quot;)&#123; myChart.setOption(option,true); &#125;&#125; &emsp;&emsp;在这里我选用的是柱形图展示用户考勤信息，并且使用的是渐变的效果，页面展示效果在文末进行展示。 5.客户端返回的json数据&emsp;&emsp;由第三步中的代码可以看出:我在图表中将考勤的日期定为柱形图的横坐标，而将考勤的时间定为柱形图的纵坐标。在控制台打印出的json数据 6.Echarts在页面上的展示]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>web项目</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[thymeleaf 基本语法]]></title>
    <url>%2F2018%2F03%2F11%2F%E6%A8%A1%E6%9D%BF%E8%AF%AD%E8%A8%80thymeleaf%E7%9A%84%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;最近加班不多，回宿舍闲的无聊，所以就将原先写的项目进行了一次大的改造，顺便学习一下thymeleaf模板语言，改造过程中还是遇到了许多的问题。二次开发等于重新开发，这句话还是很有道理的。现在项目已经改造的差不多了，所以写篇博客记录下在使用thymeleaf过程中所遇到的问题。 基本语法&emsp;&emsp;thymeleaf是spring boot官方强烈推荐的模板语言,两者的理念是很接近的，spring boot强调的是快速开发，而thymeleaf又是原型即页面。另外thymeleaf更适合前后端分离的项目，值绑定都是基于html的DOM元素属性的，适合前后连调。 基本用法 页面上引入thymeleaf 语法 12&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot; lang=&quot;zh&quot;&gt; 直接输出文本 1&lt;span th:text=$&#123;user.userName&#125;&gt;Tom&lt;/span&gt; &emsp;&emsp;将userName的值打印出来，替换掉文本域中的Tom。如果userName不存在，直接输出Tom. 基本的赋值1&lt;span th:value=$&#123;user.userName&#125;&gt;&lt;/span&gt; &emsp;&emsp;将userName的值给value，在浏览器中被解析成”“ if unless条件判断123456&lt;span th:if=($&#123;userName&#125;==Tom) &lt;div&gt;......&lt;/div&gt;&lt;/span&gt;&lt;span th:unless=($&#123;userName&#125;==Tom) &lt;div&gt;......&lt;/div&gt;&lt;/span&gt; &emsp;&emsp;判断userName是否为Tom,如果是则执行上面一个div,否则执行下面的div 页面内容的替换1&lt;head th:replace=&quot;common/header::header&quot;&gt; &emsp;&emsp;引入common文件夹中的header文件中的header模块，此功能主要是抽取出页面中的公共部分，然后替换到所需要使用页面中。功能相同的用法还有两种：th:include、th:insert 三者主要的区别在于： th:include: 保留自己的主标签，不要th:fragment的主标签(thymeleaf 3.0之后不再推荐)。 th:insert: 保留自己的主标签，保留th:fragment的主标签。 th:replace: 不保留自己的主标签，保留th: fragment的主标签。 时间格式的输出1th:text=&quot;$&#123;#dates.format(item.operateTime,&apos;yyyy-MM-dd HH:mm:ss&apos;) &emsp;&emsp;将操作时间格式化成yyyy-MM-dd HH:mm:ss的形式输出。 url用法 1&lt;li&gt;&lt;a th:href=&quot;@&#123;/loginOut&#125;&quot;&gt;退出&lt;/a&gt;&lt;/li&gt; 文件的引入 1&lt;script type=&quot;text/javascript&quot; th:src=&quot;@&#123;/js/application.js&#125;&quot;&gt;&lt;/script&gt; &emsp;&emsp;将application.js文件引入到thymeleaf页面中 th:block1&lt;th:block th:text=$&#123;user.userName&#125;&gt; &emsp;&emsp;区块操作主要用于便捷操作,比如循环,可以在dom外部形成包裹,解析之后block模块会被注释掉. 中级用法 集合的遍历1&lt;tr th:each=&quot;item:$&#123;lists&#125;&quot;&gt;......&lt;/tr&gt; &emsp;&emsp;将lists集合遍历拆分成对象，用item接收。当使用这种用法时，同时还会产生一个itemStat的对象，itemStat称为状态变量，主要属性包括： index: 当前迭代对象的index(从0开始计算) count: 当前迭代对象的index(从1开始计算) current: 当前迭代变量 even/odd: boolean值，判断是不是奇偶行 size: 被迭代对象的大小 first: 布尔值，判断循环是否是第一个 last: 布尔值，判断循环是否是最后一个 th:onClick用法12&lt;a th:onclick=&quot;&apos;javascript:layer_update(\&apos;&apos;+$&#123;item.userId&#125;+&apos;\&apos;)&apos;&quot;&gt;.......&lt;/a&gt;&lt;a th:onclick=&quot;&apos;javascript:admin_del(\&apos;&apos;+$&#123;item.userId&#125;+&apos;\&apos;)&apos;&quot;&gt;......&lt;/a&gt; &emsp;&emsp;以上用法主要是将变量值传到调用的方法中，也可以传整个对象。** 注意写法必须是以上形式，javascript:不能少也不能写错，起一个声明的作用，后面的(\’’+${item.userId}+’\’)字符斜杠也必须要写对，表示转义字符。 th:attr 用法1th:attr=&quot;data-href=$&#123;menuItem.menuUrl&#125;,data-title=$&#123;menuItem.menuName&#125; &emsp;&emsp;经浏览器解析后输出结果: data-href=”…” data-title=”…”,…表示对应的url、name数据。 th:line用法1&lt;script th:src=&quot;@&#123;/js/permission/user/userAdd.js&#125;&quot; th:inline=&quot;javascript&quot;/&gt; &emsp;&emsp;使用以上用法引用js文件，在js中就可以使用当前html页面中的对象了。在js中使用”varpage=[[${lists.pages}]];”即可调用lists对象。 用法实例 循环输出语法123456&lt;tr class=&quot;text-c&quot; th:each=&quot;item:$&#123;lists&#125;&quot;&gt; &lt;td&gt;&lt;input type=&quot;checkbox&quot; th:attr=&quot;value=$&#123;item.logId&#125;&quot; name=&quot;subCheck&quot; /&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;itemStat.count&#125;&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;item.typeName&#125;&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;item.userName&#125;&quot;&gt;&lt;/td&gt;&lt;/tr&gt; &emsp;&emsp;将lists集合遍历，然后输出所需要的值，一般在页面中构造表格经常用到。 2.条件判断12345678&lt;td class=&quot;td-manage&quot; th:switch=&quot;$&#123;item.status&#125;&quot;&gt; &lt;span th:case=&quot;1&quot;&gt; &lt;a style=&quot;text-decoration:none&quot; th:onClick=&quot;&apos;javascript:admin_stop(this,\&apos;&apos;+$&#123;item.userId&#125;+&apos;\&apos;)&apos;&quot; href=&quot;javascript:;&quot; title=&quot;停用&quot;&gt;&lt;i class=&quot;Hui-iconfont&quot;&gt;&amp;#xe631;&lt;/i&gt;&lt;/a&gt; &lt;/span&gt; &lt;span th:case=&quot;0&quot;&gt; &lt;a style=&quot;text-decoration:none&quot; th:onClick=&quot;&apos;javascript:admin_start(this,\&apos;&apos;+$&#123;item.userId&#125;+&apos;\&apos;)&apos;&quot; href=&quot;javascript:;&quot; title=&quot;启用&quot;&gt;&lt;i class=&quot;Hui-iconfont&quot;&gt;&amp;#xe615;&lt;/i&gt;&lt;/a&gt; &lt;/span&gt;&lt;/td&gt; &emsp;&emsp;以上用法中status表示用户是否已经启用，当status等于1时，表示用户已启用，所以在操作框中应该显示是停用的按钮。反之同理。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>模板语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis多表关联批量操作]]></title>
    <url>%2F2018%2F02%2F11%2Fmybatis%E5%A4%9A%E8%A1%A8%E5%85%B3%E8%81%94%E6%89%B9%E9%87%8F%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;最近在开发一个可持续集成平台devops，在开发时涉及到了批量操作，关键是数据库还都是多张表关联的，由于以前对这方面接触比较少，所以还是感觉比较困难的。经过几天的学习和实践，最终还是成功实现了。代码还未优化，所以有些粗糙，先写篇博客记录下，后续会进行代码的优化。 为什么要执行批量操作&emsp;&emsp;MyBatis操作数据库时经常会出现批量操作，例如：批量新增，批量修改，批量删除。批量操作要比数据循环执行的效率要高很多，特别是当需要操作的数据量特别大的情况下。循环执行每次都需要跟数据库建立一个连接，当连接数达到连接池上限时，系统会直接瘫痪。所以循环执行操作数据库尽量不要采用。 foreach标签foreach主要是用在构建in条件中，它主要是在SQL语句中进行循环迭代一个集合。foreach标签的主要属性有collection、index、item、separator、open、close。&emsp;&emsp; collection最容易出错，该属性在使用前必须先指定。根据传过来的参数，一般可以有三种类型（list、array、map）。&emsp;&emsp; index指定一个名字，用于在迭代的过程中迭代到的位置。&emsp;&emsp; item表示集合中每一个元素进行迭代时的别名。&emsp;&emsp; separator指定在迭代时以什么符号作为分隔符。&emsp;&emsp; open、close表示语句以什么开始，以什么结束。 多表关联mybatis关于多表关联有相应的处理办法，提供了association和collection两个标签。&emsp;&emsp; association通常是用来对应一对一的关系。&emsp;&emsp; collection通常是用来对应一对多关系或者是多对多的关系。但是因为项目是前后端分离，公司自己封装了框架，对复杂类型的数据不太友好，加上项目数据量也不算太大，所以没有使用这两个标签，而是直接新建一个实体类包含两张表里面的共同数据，然后在mapper中映射到创建的实体即可。 批量增加在添加的过程中，其它的字段都相同，但是可以输入多个IP,有多少个IP,就在数据库中添加多少条数据实现批量新增。在项目中，前台传给后台一个对象AppInfoFilter,因为有部分字段需要转换，所以需要将字段转换后封装到集合然后返回前台。核心代码如下： 数据的转换先将前台传过来的数据进行转换，然后将多个IP进行拆分，将所有字段封装到一个新的对象，最后将这个对象封装成集合传到mapper中进行批量增加。12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Transactional(isolation = Isolation.READ_UNCOMMITTED, propagation = Propagation.REQUIRED)@Overridepublic ResList&lt;AppInfo&gt; save(AppInfoFilter appInfoFilter) &#123; List&lt;String&gt; record=appInfoFilter.getHostIp(); List&lt;AppInfo&gt; list=new ArrayList&lt;&gt;(); //通过主体名称查询主体编号，然后将主体编号存入cm_host_system String projectName=appInfoFilter.getProjectName(); CmProject cmProject=cmProjectMapper.selectByName(projectName); //通过组件名称去应用组件表中查询组件类型，然后将组件类型存入cm_app_components String appType=appInfoFilter.getAppType(); List&lt;CmComponents&gt; list1=cmComponentsMapper.selectByName(appType); //通过systemName去cm_system表中查询system_id,然后存入cm_host_system String systemName=appInfoFilter.getSystemName(); List&lt;CmSystem&gt; list2=cmSystemMapper.selectByName(systemName); //将AppInfo封装成一个list集合 for (String hostIp:record) &#123; AppInfo appInfo = new AppInfo(); appInfo.setUuid(UUID.getUUID()); appInfo.setHostId(hostIp); appInfo.setHostIp(hostIp); appInfo.setCreateTime(new Date()); appInfo.setAppId(appInfo.getUuid()); //将其它的转换抽取出来 convert(appInfoFilter); //通过其他的信息查询出来的信息 appInfo.setProjectNum(cmProject.getNumber()); appInfo.setType(list1.get(0).getType()); appInfo.setSystemId(list2.get(0).getNumber()); list.add(appInfo); &#125; //先向关联表cm_host_system中添加数据 hostMapper.batchInsert(list); //再向参数表中添加数据 paramMapper.batchInsert(list); componentsMapper.batchInsert(list); ResList&lt;AppInfo&gt; resList=new ResList&lt;AppInfo&gt;(list); return resList;&#125; 代码未进行优化，所以看起来有点乱。由于是三张表关联，所以分别想三张表中插入数据（找了好久资料也想了很久也没实现一条SQL实现三张表插入）。 将集合中的数据插入到数据库中执行单表批量增加的SQL语句：1234567891011121314151617&lt;insert id=&quot;batchInsert&quot; parameterType=&quot;java.util.List&quot;&gt; insert into cm_app_components (UUID, APP_TYPE, APP_VERSION, TYPE, HOST_ID, HOST_IP, PORT, DESCRIPTION, CREATE_TIME, UPDATE_TIME, SCRIPT_PATH ) VALUES &lt;foreach collection=&quot;list&quot; item=&quot;item&quot; index=&quot;index&quot; separator=&quot;,&quot;&gt; (#&#123;item.uuid,jdbcType=VARCHAR&#125;, #&#123;item.appType,jdbcType=VARCHAR&#125;, #&#123;item.appVersion,jdbcType=VARCHAR&#125;, #&#123;item.type,jdbcType=VARCHAR&#125;, #&#123;item.hostId,jdbcType=VARCHAR&#125;, #&#123;item.hostIp,jdbcType=VARCHAR&#125;, #&#123;item.port,jdbcType=VARCHAR&#125;, #&#123;item.description,jdbcType=VARCHAR&#125;, #&#123;item.createTime,jdbcType=TIMESTAMP&#125;, #&#123;item.updateTime,jdbcType=TIMESTAMP&#125;, #&#123;item.scriptPath,jdbcType=VARCHAR&#125;) &lt;/foreach&gt;&lt;/insert&gt; 对于单表来说，批量增加还是比较简单的。但是这样非常消耗连接池资源。长久肯定是不可能的。 批量修改由于项目中此模块涉及到的字段太多，但是客户要求只有几个字段能够修改，其它字段全部设为不可修改状态，所以批量修改还是比较轻松的。类似于批量增加，还是先将要批量修改的对象封装成集合。 数据的封装AppUpdateInfo 实体中只有四个字段，，替换掉AppInfo中的旧数据，将AppInfo封装成一个集合，然后利用SQL语句进行多表关联修改即可。1234567891011121314151617181920//批量修改@Transactional(isolation = Isolation.READ_UNCOMMITTED, propagation = Propagation.REQUIRED)@Overridepublic ResList&lt;AppInfo&gt; batchUpdate(AppUpdateInfo updateInfo) &#123; List&lt;String&gt; record=updateInfo.getUuid(); List&lt;AppInfo&gt; list=new ArrayList&lt;AppInfo&gt;(); for (String uuid:record)&#123; AppInfo appInfo=new AppInfo(); appInfo.setUuid(uuid); appInfo.setAppVersion(updateInfo.getAppVersion()); appInfo.setScriptPath(updateInfo.getScriptPath()); appInfo.setDeployDir(updateInfo.getDeployDir()); appInfo.setAppDir(updateInfo.getAppDir()); appInfo.setUpdateTime(new Date()); list.add(appInfo); &#125; appMapper.batchUpdate(list); ResList&lt;AppInfo&gt; resList=new ResList&lt;AppInfo&gt;(list); return resList;&#125; 将数据库中的数据进行修改先将几张表进行关联，然后进行批量更新。1234567891011121314&lt;update id=&quot;batchUpdate&quot; parameterType=&quot;java.util.List&quot;&gt; &lt;foreach collection=&quot;list&quot; separator=&quot;,&quot; item=&quot;item&quot; index=&quot;index&quot;&gt; UPDATE cm_app_components c LEFT JOIN cm_app_components_param p ON c.UUID=p.APP_ID SET c.APP_VERSION = #&#123;item.appVersion&#125;, c.SCRIPT_PATH = #&#123;item.scriptPath&#125;, p.DEPLOY_DIR = #&#123;item.deployDir&#125;, p.APP_DIR = #&#123;item.appDir&#125; WHERE c.UUID = #&#123;item.uuid&#125; &lt;/foreach&gt;&lt;/update&gt; 批量删除批量删除根据传入的多个uuid进行删除，只需要在SQL中将多张表关联，然后用foreach遍历封装了uuid的list集合进行删除即可。核心代码如下：123456789&lt;delete id=&quot;batchDelete&quot; parameterType=&quot;java.util.List&quot;&gt; DELETE c,s FROM cm_db_components c LEFT JOIN cm_db_system s ON c.UUID=s.P_UUID WHERE c.UUID IN &lt;foreach collection=&quot;list&quot; item=&quot;item&quot; index=&quot;index&quot; separator=&quot;,&quot; open=&quot;(&quot; close=&quot;)&quot;&gt; #&#123;item&#125; &lt;/foreach&gt;&lt;/delete&gt; 技术太low，代码写的很差，很多地方都可以优化，而且有些控制都没有加上。但是写这份代码对我的帮助挺大的，对mybatis的使用熟悉了很多。虽然这是我做的第二个项目，但是却走了整个的流程。学到的东西挺多的。]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ArrryList和LinkedList的区别]]></title>
    <url>%2F2018%2F01%2F06%2FArrayList%E5%92%8CLinkedList%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[相同点：ArrayList和LinkedList类都位于java.util包中，均为可收缩数组，即可以动态的改变数组的长度。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[容器主要类型的区分]]></title>
    <url>%2F2018%2F01%2F03%2F%E5%AE%B9%E5%99%A8%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%8C%BA%E5%88%86%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;在学校的时候对Java容器的知识不太熟，或许是上课打瞌睡去了吧。最近重温了一下，写篇博客让自己记得更深一点。 容器的基本概念Java 容器类类库的概念是“保存对象”，通常将其划分为两个不同的概念： Collection: 一个独立元素的序列，这些元素都服从一条或多条规则。List 必须按照插入的顺序保存元素，而Set不能有重复元素。Queue按照排队规则来确定能够对象产生的顺序（通常与它们被插入的顺序相同）。 Map: 一组成对的“键值对”对象，允许你使用键来查找值。映射表允许我们使用另一个对象来查找某个对象，它也被成为“关联数组”，因为它将某些对象与另外一些对象关联在一起；或者被称为“字典”，因为你可以使用键对象来查找值对象。Map是强大的编程工具。 容器中的几种不同的存贮方式先来看一个小例子： 1234567891011121314151617181920212223242526public class PrintingContainers &#123; public static Collection fill(Collection&lt;String&gt; collection)&#123; collection.add(&quot;Snow&quot;); collection.add(&quot;White&quot;); collection.add(&quot;Star&quot;); collection.add(&quot;Wars&quot;); return collection; &#125; public static Map fill(Map&lt;String,String&gt; map)&#123; map.put(&quot;Snow&quot;,&quot;Tom&quot;); map.put(&quot;White&quot;,&quot;Jerry&quot;); map.put(&quot;Star&quot;,&quot;Jack&quot;); map.put(&quot;Wars&quot;,&quot;Angle&quot;); return map; &#125; public static void main(String[] args)&#123; System.out.println(fill(new ArrayList&lt;String&gt;())); System.out.println(fill(new LinkedList&lt;String&gt;())); System.out.println(fill(new HashSet&lt;String&gt;())); System.out.println(fill(new LinkedHashSet&lt;String&gt;())); System.out.println(fill(new TreeSet&lt;String&gt;())); System.out.println(fill(new HashMap&lt;String,String&gt;())); System.out.println(fill(new TreeMap&lt;String,String&gt;())); System.out.println(fill(new LinkedHashMap&lt;String,String&gt;())); &#125;&#125; 代码运行的结果为： 以上代码展示了Java容器类库中的两种主要类型，它们的区别在于容器中每个“槽”保存的元素的个数。Collection在每个“槽”中只能存贮一个元素。此类容器包括：List，它已特定的顺序保存一组元素；Set，元素之间不能重复；Queue，只允许在容器的一端插入对象，并从另外一端移除对象。Map在每个槽中存贮了两个对象，即一个键值对。 上面的代码中首先利用fill()方法给所有类型的Collection容器添加元素add()方法。fill()方法可以作用于所有类型的Collection。 ArrayList和LinkedList都是List类型，两者都属于可伸缩数组，可以动态的改变数组的长度。从输出的结果可以看出，它们都是按照被插入的顺序来保存元素。两者的不同之处不仅在于执行某些类型的操作时的性能，而且LinkedList包含的操作也多余ArrayList。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程的几种实现方式]]></title>
    <url>%2F2018%2F01%2F02%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%87%A0%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;线程是Java中的一个重要学习内容，有一段时间没用到，最近重温了一下。写点东西记录一下。 什么是线程？ 线程是指程序在执行过程中，能够执行程序程序代码的一个执行单元。在Java语言中，线程有四种状态：运行、就绪、挂起和结束。 为什么要使用多线程 使用多哦线程可以减少程序的相应时间。 多CPU或多核计算机本身就具有执行多线程的能力。 与进程相比，线程的创建和切换开销更小。 使用多线程能简化程序的结构，使程序便于维护和理解。一个非常复杂的进程可以分成多个线程来执行。 基本的线程机制在使用线程时，CPU将轮流给每个任务分配其占用时间。每个任务都觉得自己在一直占用着CPU,但事实上CPU时间是划分成片段分配给所有的任务。线程可以使你从这个层次抽身出来。注意：当系统使用时间切片机制时，CPU轮流给每个任务分配时间，例如Windows（线程优先级和时间片轮转调度）操作系统。但有些操作系统采用FIFO模型，除非有高优先级的线程被唤醒，否则当前线程将一直运行，直至阻塞或终止。 如何实现Java多线程继承Thread类，重写run()方法Thread 本质上也是实现了Runnable接口的一个实例，它代表一个线程的实例，并且，启动线程的唯一方法就是通过Thread类的start()方法。start()方法是一个native(本地)方法，它将启动一个新线程，并执行一个run()方法(Thread中提供的run()方法是一个空方法)。这种方式通过自定义直接继承Thread，并重写run()方法，就可以启动新线程并执行自己定义的run()方法。调用start()方法后并不是立即执行多线程代码，而是使得该线程变成可运行态，什么时候运行多线程是由CPU调度决定的 1234567891011class MyThread extends Thread&#123; public void run()&#123; System.out.println(&quot;Thread body&quot;); &#125; &#125; public class Test&#123; public static void main(String[] args)&#123; MyThread thread=new MyThread(); thread.run(); &#125; &#125; 实现Runnable接口，并实现该接口的run()方法主要步骤：1） 自定义类并实现Runnable接口，并实现run()方法。2） 创建Thread对象，用实现Runnable接口的对象作为参数实例化该Thread对象。3） 调用Thread的start()方法。 123456789101112class MyThread implements Runnable&#123; public void run()&#123; System.out.println(&quot;Thread body&quot;); &#125;&#125;public class Test&#123; public static void main(String[] args)&#123; MyThread thread=new MyThread(); Thread t=new Thread(thread); t.start(); &#125;&#125; 以上两种是实现多线程最常用的方法。 其实不管是通过继承Thread类还是通过使用Runnable接口来实现多线程的方法，最终还是通过Thread的对象的API来控制线程的。 实现Callable接口，重写call()方法Callable接口实际上是属于Executor框架的功能类，Callable接口与Runnable接口的功能类类似，但提供了比Runnable更强大的功能，主要表现在以下三点：1）Callable可以在任务结束后提供一个返回值，Runnable无法提供这个功能。2）Callable中的call()方法可以抛出异常，而Runnable的run()方法无法抛出异常。3）运行Callable可以拿到一个Future对象，Future对象表示异步计算的结果，可以使用Future来监视目标线程调用call()方法的情况，当调用Future的get()方法以获取结果时，当前线程就会阻塞，直到call()方法结束返回结果。 12345678910111213141516171819202122public class CallableAndFuture&#123; //创建线程类 public static class CallableTest implements Callable&lt;String&gt;&#123; @Override public String call() throws Exception &#123; return &quot;欢迎来到我的博客！&quot;; &#125; &#125; public static void main(String[] args)&#123; ExecutorService threadPool= Executors.newSingleThreadExecutor(); //启动线程 Future&lt;String&gt; future=threadPool.submit(new CallableTest()); try &#123; System.out.println(&quot;waiting thread to finish&quot;); //等待线程结束，并获取返回结果 System.out.println(future.get()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 上述程序的输出结果为： 以上3中方式中，前两种方式线程执行完后都没有返回值，只有最后一种带有返回值的，但是当需要使用多线程时，一般最好是使用实现Runnable接口的方式。因为Thread类定义的多中方法可以被派生类使用或者重写。但是只有run()方法是必须被重写的，在run()方法中实现了这个线程的主要功能。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git总结]]></title>
    <url>%2F2018%2F01%2F01%2Fgit%2F</url>
    <content type="text"><![CDATA[git 简介git 是一款分布式的版本控制系统，其核心是分支，分支的意义在于可以将项目代码按照功能和模块拆分为不同的分支。在 git 中，工作目录下面的所有文件都不外乎两种状态： 已跟踪和未跟踪。 已跟踪文件是指已经被纳入git中，在版本控制器中有它们的记录，但是当我们对文件进行修改之后，文件变得和git中的不一样，那么它就属于未跟踪文件。初次克隆某个仓库时，所有文件都属于已跟踪文件。 git 常用指令git pull作用 将远程代码仓库里的代码下载下来并自动整合到当前工作分支 用法： git pull origin master 将origin这个版本库中的代码更新到本地的master主支，类似于SVN的update git add作用 是将当前更改或者新增的文件加入到Git的索引中，加入到Git的索引中就表示记入了版本历史中，这也是提交之前所需要执行的一步 用法： git add app/model/user.java 增加app/model/user.java文件到Git的索引中,该功能类似于SVN的add git rm作用 从当前的工作空间中和索引中删除文件 用法： git rm app/model/user.java 删除工作空间中或者索引中的app/model/user.java文件，该功能类似于SVN的rm、del git commit作用 将所有添加到索引库的文件添加到本地仓库文件一旦commit之后，就会在git中形成一个历史版本，以后无论怎么变都能够找到此次提交的记录。 用法： git commit -m story #3, add user model 提交的时候必须用-m来输入一条提交信息，该功能类似于SVN中的commit git push作用 将本地仓库中的修改推送到远程仓库 用法：git push origin 将本地的代码推送到名为origin的远程版本库中 git log作用 查看git的历史日志 该功能类似于SVN的log git revert作用 还原一个版本的修改，必须提供一个具体的Git版本号，Git的版本号都是生成的一个哈希值 用法：git revert bbaf6fb5060b4875b18ff9ff637ce118256d6f20]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F12%2F30%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
